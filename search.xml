<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[MyCat简介]]></title>
      <url>%2F2017%2F08%2F18%2FMyCat%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[什么是分布式数据库中间件在传统架构中，应用直接连接到数据库中直接对数据进行访问，但是随着数据量不断增大，就会有一些性能上的问题，比如但数据库中表太多，表中数据太多，单服务器压力大，读写速度遇到瓶颈等问题。 当面临上述问题时，可行的解决办法是向上扩展，不断增加硬件的性能，但这样做一是成本高二是不易拓展；还有一个办法是水平扩展，将单数据库拆分在不同的服务器不同的数据库中，使用时，直接访问一个代理数据库，这个代理数据库向下连接着不同的数据库，向上对用户抽象成一个数据库，且数据库的分布对用户是透明的。这个代理数据库就是分布式数据库中间件。 MyCat是什么MyCat是一个开源的分布式数据库中间件，是一个实现了MySQL协议的，向下通过MySQL协议访问MySQL实例和通过JDBC访问主流的商业数据库，向上对用户抽象成一个逻辑库，核心功能分库分表且对用户透明的具有高并发、高可用、高性能的数据库中间件。 MyCat有什么用当业务量数据量非常庞大，存储在单个数据库中受到性能瓶颈，希望通过水平拆分数据库但同时又要像访问单数据库一样方便快捷可靠的时候，采用MyCat数据库中间件可以满足上述的需求。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[NIO中的同步与非阻塞]]></title>
      <url>%2F2017%2F08%2F17%2FNIO%E4%B8%AD%E7%9A%84%E5%90%8C%E6%AD%A5%E4%B8%8E%E9%9D%9E%E9%98%BB%E5%A1%9E%2F</url>
      <content type="text"><![CDATA[脑子烧的慌早上看到了一些Java序列化的应用，不知道怎么那个人扯到了NIO，然后我突然想起了SOA中的的RPC服务，这种远端提供服务时很有可能会用到序列化传输对象，然后又为了在分布式条件下具有高并发的性能，所以很有可能会用到NIO来传输数据。接着，我就开始回忆NIO的一些细节，突然间就不能想起来NIO提供同步还是非同步，阻塞还是非阻塞IO了。查资料查了一堆，概念定义解析看了不少，人是越来越懵逼了，究竟这些概念是什么意思，怎么理解，怎么应用？看了好久，脑子感觉明显发热，好在后面看了知乎上一个人的解释，瞬间就是一个醍醐灌顶，一下子理顺了之前的思维。鉴于过程艰辛困苦，在这里特意总结一下。 NIO是同步非阻塞IONIO是同步非阻塞式IONIO是同步非阻塞式IONIO是同步非阻塞式IO首先我要把这句话说三遍，因为之前我一度忘记了NIO的特点。但是我个人之前对与这个同步与非阻塞体现在哪里不是很理解。 我们都知道，NIO是有三个基本的构件：Selector、Channel和Buffer。Channel向Selector中注册不同的兴趣事件，然后Selector会负责监听Channel中是否有注册的事件发生，如果有需要读写的操作，Channel又会使用Buffer来缓存数据，用于之后操作；Selector可以被多个Channel注册，这样一个主线程中的Selector就可以监视多个Channel（可能会位于多个线程）发生的事件。 在NIIO基本概念的基础上，我们来看这些在IO中常见词的概念 同步与异步站在程序的角度上， 同步：用户程序在发起操作后，需要不断的轮询操作是否完成（或准备就绪），如果没有完成（就绪）导致程序“卡住”，无法继续向下运行；直到操作完成才通知程序继续 异步：用户程序发起操作后，便不再关注操作的具体是否执行以及执行的内容；当操作完成之后，会自动回调或其它通知方式来通知程序 阻塞与非阻塞站在线程的角度上， 阻塞：当主线程发起一个操作时，具体执行时该线程就一直等，直到等到实际的操作完成之后，线程才会继续 非阻塞：当一个主线程发起操作后，具体执行的方法会分出独立的线程去执行这个操作，主线程是继续向下运行的，而不是傻傻的等待 再来看同步与非阻塞看完了上面的概念后，可以注意到的是，同步与非阻塞关注的点不同，同步与异步是说消息的通知机制，而阻塞与非阻塞说的是线程的状态 回过头来看NIO的同步与非阻塞首先我们要先明确一点，Java最底层的IO操作是同步的，但是NIO是一个经过包装的IO操作，是在selector机制实现的事件驱动包装下，对外提供同步非阻塞的功能。 具体体现在，Selector的select()方法会轮询Channel中的事件是否就绪（这是同步），在主线程中的Selector可以监听多个Channel注册的事件，如果有事件发生自然会分配Channel去处理，这样主线程并不会阻塞（这是非阻塞） MyCat中的NIO应用MyCat的通信模型中，是有使用到NIO的，对应了Reactor模式的通信机制 NIOAcceptor负责轮询是否有连接事件，如果有就将连接放到队列中交给NIOReactor负责，NIOAcceptor继续轮询接下来是否有连接（这是基于Reactor事件驱动的编程模型提供了异步操作） 后端NIOConnector也会负责后端连接事件，同样把连接放到队列中交给NIOReactor处理 NIOReactor会分出独立处理读写事件的RW线程来完成具体的读或者写 读写后会将数据交给专门处理业务的工作线程去通过Handler的方法进行下一步的处理 其实上面提到了MyCat的通信模块与线程模块，具体的线程模块会在以后分析 我说首先是一种混沌之后的豁然开朗，随后而来的是一种劫后余生的幸运。之前确实是被绕晕了，像是之前的Java中的编码问题一样。被绕晕过的人都会懂，脑海中是各式各样的概念，杂七杂八的混杂在一起，理不出思绪，甚至是原来已经具有的理解也被忘记或者颠覆。我很清楚这样下去很有可能在耐心耗尽之时匆匆得出一个错误的结论，这对个体知识体系的建立是灾难级别的打击。不过回过头来也只能说这是对于基本概念理解的问题，今天我解决了，写下了这篇自己的总结，希望可以给别人提供一点点微小的帮助。 知乎链接：Java NIO不是同步非阻塞IO吗，怎么还会….]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MyCat通信模块]]></title>
      <url>%2F2017%2F08%2F16%2FMyCat%E9%80%9A%E4%BF%A1%E6%A8%A1%E5%9D%97%2F</url>
      <content type="text"><![CDATA[开始的地方这是我了解MyCat开始的地方，当然现在也要回过头来再看一下，同样的，也从这里开始吧之前看了很多资料，十分感谢前者的分享，正是他们的存在与热心分享，我才有机会去接触和学习，这里也挂一下参考资料：一篇文章让你成为 NIO 大师 － MyCAT通信模型数据库分库分表（Mycat等）-张哈希本文以总结自己的理解与收获为主，难免引荐上面大佬的博文 通信执行过程首先我要贴一张图MyCat前端与后端都可以使用NIO和AIO进行通信，但是现在的服务器大都是使用Linux系统，而Linux不支持AIO，使用起来性能甚至远比不上NIO，所以就只从NIO通信基础出发来理解整个MyCat通信模块 这里先不讲MyCat启动的过程，后面的文章再继续谈，我们先来看看MyCat通信模块中的前端连接模块。 前端连接模块注册连接首先是NIOAcceptor负责处理整个前端的连接请求，这里的前端指的是应用与MyCat之间的连接请求。NIOAcceptor初始化时，会新建新的selector和serverSocketChannel，并将其绑定端口、IP等信息，然后向selector注册这个serverSocketChannel，感兴趣的事件是OP_ACCEPT；接下来NIOAcceptor由于继承了Thread类，在run方法中获取了selector的拷贝tSelector，然后调用select()方法阻塞式轮询是否有连接请求。当有连接请求时，NIOAcceptor会调用accept()方法，获取socketChannel，并设置为非阻塞，使用前端连接工厂FrontendConnection获取一个封装了的前端连接，然后将连接与socketChannel绑定，从NIOProcessor池中获取NIOProcessor，用来管理前端连接，并将从NIOReactor池中获取的NIOReactor实例与前端连接绑定，然后将连接请求交给NIOReactor去处理。 前端认证接下来看NIOReactor,NIOAcceptor将连接传递过来以后，连接实例被放到了一个ConcurrentLinkdQueue等待队列中，同时唤醒内部线程类RW，用来从队列中取出连接实例；每一个RW线程都有一个专属的selector，在run()方法中循环调用select()方法轮询连接事件；当有连接请求时，RW线程会调用register()方法去从连接队列中去除连接请求实例，再将连接中取出的NIOSocketWR的通道注册到selector上，注册的感兴趣的事件是OP_READ，随后，调用FrontendConnection中的register()方法生成握手包，MyCat与应用建立TCP连接后，发送该握手包。接着就是等待应用发回认证包，这里会调用NIOSocketWR的asyRead()f方法进行异步读；从缓冲池中获取到buffer准备接收数据，实际上还是AbstractConnection中的onReadData()方法去读连接中来自应用的数据，将应用发来的认证包读取到buffer中，再交予不同功能的handler去处理这些数据，在这里我们进行的是前端认证，所以使用FrontendAuthenticator类对象进行认证包的解析与认证，这里认证的信息是配置在server.xml中的MyCat-Server的用户信息，认证成功后，将AbstractConnection中的handler替换成FrontendCommandHandler类的对象，准备处理来自应用的命令行SQL语句；然后向应用写回OK，正式建立了前端连接； 读取前端SQL语句接下来再回到NIOReactor中的RW线程中，run()方法注册了连接后，前面说了selector注册的是OP_READ事件，这里就会在当有数据写入到channel中且读事件就绪后，RW线程会判断一下究竟是写事件还是读事件（因为RW线程读写复用），然后调用连接实例接着AbstractionConnection真正开始读取数据，然后将数据交给FrontendCommandHandler实例来处理这些数据（命令或SQL语句）。在这里我想引入一段别人的话，我觉得说的很好，当时清除的让我认识到了一些模糊的地方： 前面反复提到一个词：连接实例，究竟什么是连接实例？客户端发往MyCAT的每一次请求，以及MyCAT发往MySQL的每一次请求，都是一个连接实例。可以把连接实例看作是一次请求事件的主干，我们都知道，NIO是一个同步非阻塞的 I/O 模型。阻塞的线程没有做任何有意义的事情，却依然消耗系统资源，这是我们不能接受的，所谓非阻塞，就是不断的在这条主干上衍生分支，来处理复杂的业务请求，这样主干就不会阻塞。而同步，是指线程不断轮询 IO 事件是否就绪，主干上衍生的这些分支，都维护了一个Selector对象，Selector代替了主干线程来执行这种轮询，包括前面讲到的acceptor和reactor；这些分支线程是以线程池的形式存在的，是可以复用的，从而减少了频繁创建、启动、挂起、析构新线程的开销，大大提升系统的并发效率。 另外这里会有一个很有意思的地方，就是MyCat会根据不同的情况，调用不同的handler来处理读取到的数据；首先从channel中读取字节流形式的数据，按照MySQL协议进行数据的拆包，判断是什么类型的信息，如果是认证信息，就让负责认证的handler来处理，如果是SQL语句，就让负责解析SQL的handler来处理，后面还会说到有不同的处理后端信息的handler，它们都来自同一个接口NIOHandler，MyCat的AbstractionConnection连接实例是前后端连接实例的抽象，所有的数据处理都是在这里读取并交给不同的handler处理，感觉这种用法很是精髓 解析SQL当准备开始解析SQL的时候，具体的handler会开始进行一次浅解析，根据SQL语句的CURD关键词，并判断语句是否需要发送到后端，来再次精确到不同操作的handler，这里先不讲，等日后分析到MyCat的路由解析模块时再添上链接，假设现在已经选取了合适的handler，执行的细节也先不提，我们接下来看后端连接模块 后端连接模块后端连接与前端连接绑定后端连接实例也是通过工厂生成的，当处理SQL语句的handler需要操作后端连接实例的时候，例如查询，ServerQueryHandler中的ServerConnection会调用execute()方法，进行SQL语句的路由计算，得到RouteResultSet路由计算结果，里面包含了路由信息，接着ServerConnection中的NonBlockingSession实例会调用execute()方法，判断路由信息单节点还是多节点，然后合适的NodeHandler会判断是否在NonBlockingSession中存在后端连接，其实这个session早在前端连接由工厂方法创建的时候就已经唯一的绑定了，这个会话里保存了所有的前后端连接涉及的信息；如果session中没有后端连接或者连接已经过期，需要调用PhysicalDBPool和PhySicalDataSource到具体的某个数据源中去获取连接，这里会涉及到负载均衡和writeHost以及readHost，后端连接MySQLConnection是由MySQLConnectionFactory的make()方法创建，这里会配置连接的端口、IP、用户、密码等，然后设置AbstractConnecion中的handler为MySQLConnectionAuthenticator，准备后面的后端认证；然后将该连接实例交给NIOConnector去注册和认证 后端认证在继承了Thread类的NIOConnector中，同样会将连接放到一个缓冲队列中，然后唤醒selector，注册OP_CONNECT事件，然后连接中的socketChannel主动向MySQL发起连接，然后在run()方法中将后端连接实例与NIOProcessor实例绑定在一起（NIOProcessor负责管理前后端连接），然后将socketChannel交给NIOReactor去注册，像前端连接注册一样；放到连接队列中，唤醒selector，监听读事件，然后调用AbstractConnection的异步读，这是因为连接到MySQL实例时，MySQL会主动发回握手包；接下来会调用后端验证的handler去处理读取的数据；握手成功后MyCat发送认证数据，这些也配置在schame.xml中数据源实例中，发送数据是将数据存储在buffer中，然后放到写缓冲队列中，调用NIOSoketWR的doNextWriteCheck()方法，使用CAS获取写锁，然后将缓冲队列中的数据一次性全部写入到socketChannel中；如果没有写完或者是又有新的buffer放入到写缓冲队列中，则继续注册写事件，否则取消注册写事件；然后再回到NIOReactor中，因为已经注册了读事件且需要读取MySQL实例返回的OK_Packet，这时AbstractConnection中的handler已经又换成了MySQLConnectionHandler，用来处理MySQL返回的结果集 后端发送SQL语句得到合适的认证过的后端连接后会调用PhysicalDataSource中的takeCon()方法，然后会将之前传入session设置为后端连接实例的回调，将前端连接和后端连接绑定在了一起，这一步很重要，后短链接需要来自前端连接的SQL，前端连接需要来自后端的结果集，当然了这里的前后端连接都是可以复用的；session获取了具体的经过认证的后端连接实例后，实际会由MySQLConnection调用execute()方法，接下来是真正处理SQL语句的地方，已经经过路由计算的SQL语句是被加工过的，会按照MySQL协议封装成数据包，然后放到写缓冲队列中，接下来像验证时一样，写完数据，便等待MySQL返回结果，并异步读取结果交给响应的MySQLConnectionHandler处理； 后端接收MySQL返回的结果集MyCat接收到返回的结果集之后，根据结果集的内容分为三个阶段进行解析，具体的过程这里不细说，处理之后的数据交给了SingleNodeHandler，准备将其交给前端连接；这里并没有直接将数据传给前端连接，而是通过以二进制包的形式写入到buffer中，再放入到写缓冲队列，由前端连接将结果的二进制包写到socketChannel中，返回给应用；至此，整个MyCat的通信模块流程已经走了一遍 MyCat的NIO通信模型查资料时，看到了一张图，感觉很是到位此之谓Reactor模型，和AIO对应的是Proactor模型，这种实现了真正的异步模式，但是我们在这里只分析NIO的情况 一点小的感想分布式数据库中间件MyCat作为一款开源的分布式组件，具有高性能、高可用、高并发的特点，基于Cobar但是更胜于闭源前的Cobar，和HotDB一样都是Cobar的衍生产品。它是我学习分布式数据库的入门，更是我了解分布式技术的入门，从这里开始我仿佛也进入了新世界，不再将眼光局限于Java的后台开发，因为有更好玩更有意思的东西，更新潮更牛逼的技术。 有时想想，原理很简单却又很巧妙，是这些精心雕琢的产品才造就了Java开发的常青以及盛世，虽然近年来AI是热门，但是我还是更倾心于这种基础组件，就是因为它们是基础，是可以作为任何技术和应用的核心。也正是因为它们的不可替代性，让我更加对阿里巴巴这家公司的技术充满了向往。 之前看过的一本书《淘宝技术这十年》，当时对一些技术不够了解，并没有觉得多么称奇，现在看来，那些技术无愧于伟大二字，他们那些大牛承担了从无到有的工作，所以才有了支撑淘宝海量业务的强大组件，有了Cobar，有了MyCat，有了分布式数据库现在百花盛开的场面。今天刚看到的消息，华为也推出了他们的分布式数据库中间件DDM，可以遇见的是在未来，分布式技术必将长盛不衰。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java中各种锁的概念]]></title>
      <url>%2F2017%2F08%2F10%2FJava%E4%B8%AD%E5%90%84%E7%A7%8D%E9%94%81%E7%9A%84%E6%A6%82%E5%BF%B5%2F</url>
      <content type="text"><![CDATA[参考资料 Java并发编程：Synchronized及其实现原理：详细的介绍了Synchronized的原理 关于Java中的锁：大概介绍了集中常见的概念 聊聊并发（二）——Java SE1.6中的Synchronized：介绍了轻量级锁的原理，对比了不同种锁的优劣，真大牛 进程的挂起与阻塞：大概介绍了挂起与阻塞的区别 多线程之：偏向锁，轻量级锁，重量级锁：主要是看了轻量级锁与重量级锁的区别，但也有杂七杂八汇总的原理 jvm从轻量级锁膨胀到重量级锁是在什么时候发生的？：锁膨胀时的细节 Java轻量级锁原理详解(Lightweight Locking)：主要看轻量级锁的实现原理 Java中CAS详解：详细介绍了CAS原理作用]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java中String类型与默认字符编码]]></title>
      <url>%2F2017%2F08%2F08%2FJava%E4%B8%ADString%E7%B1%BB%E5%9E%8B%E4%B8%8E%E9%BB%98%E8%AE%A4%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%2F</url>
      <content type="text"><![CDATA[为什么写这个至于为什么要写这个，主要是一句mmp一定要讲，绕了一上午，晕死Java程序中的中文乱码问题一直是一个困扰程序员的难题，自己也不例外，早在做项目时就遇到过很多编码方式的坑，当时想填来着，但是嫌麻烦。这次终于忍不住了，一定要弄个明白 String类型的编码方式从网上查的资料都说，Java默认的字符编码是Unicode，而String类型的编码方式是与JVM编码方式和本机操作系统默认字符集有关的。于是我做出了测试在Java中可以这样显示查看本地编码方式（JVM还是OS呢？）12// Gets the system property indicated by the specified key.System.out.println(System.getProperty("file.encoding")); 看注释上说是获取系统字符集，但是我对这个系统的概念表示存疑，为什么呢，因为众所周知，我们中国人的电脑大部分默认的字符编码方式就是GBK，在CMD中输入chcp可以获得一个数值936，这就表示了是GBK的编码方式。但是我自己运行出这句话的结果竟然是UTF-8，我是在IDEA中运行的，并且已经使用IDEA设置了项目的编码方式是UTF-8，出现这样的结果我只能是猜测其实上面这句话是获取JVM（跟随项目的编码方式）的编码方式 接下来我们来回归正题，String类型的默认编码方式是什么，有下面这几句语句:123456789/* 测试String类型默认的编码方式*/// 使用String的有参构造方法String str = new String("hhhh ty智障%shfu摸淑芬十分uif内服NSF黑i飞鸟回复额u发为呢丶u 房未婚夫未婚夫");// 1.以GBK编码方式获取str的字节数组，再用String有参构造函数构造字符串System.out.println(new String(str.getBytes("GBK")));// 2.以UTF-8编码方式获取str的字节数组，再以默认编码构造字符串System.out.println(new String(str.getBytes("UTF-8"))); 下面来看一下运行结果：12345// 1.hhhh ty����%shfu�����ʮ��uif�ڷ�NSF��i����ظ���u��Ϊ��ؼu ��δ���δ��� hhhh ty智障%shfu摸淑芬十分uif内服NSF黑i飞鸟回复额u发为呢丶u 房未婚夫未婚夫// 2.hhhh ty智障%shfu摸淑芬十分uif内服NSF黑i飞鸟回复额u发为呢丶u 房未婚夫未婚夫 可以很明显的可以看出，这里String类型默认的字符编码方式就是与我们查看本地系统的编码方式相同。因此我们得出结论：String类型的默认编码方式是和本地编码方式相关 String.getBytes()方法我们大多数情况下是不使用String类型的，而是使用byte数组来传输操作数据，一般会使用String.getBytes()方法来将字符串转换成字节数组。但是这样转换的时候，会不会牵涉到编码问题呢？仔细查看了String.getBytes()的源码，分为无参的和有参的两种：12345678910111213// 1.无参的getBytes()方法 public byte[] getBytes() &#123; // 再继续深入encode()方法可以发现使用的是系统默认的字符编码 return StringCoding.encode(value, 0, value.length); &#125;// 2.带参数的getBytes(String charsetName)方法 public byte[] getBytes(String charsetName) throws UnsupportedEncodingException &#123; if (charsetName == null) throw new NullPointerException(); // 继续深入可以发现，会使用参数字符集编码方式来返回字节数组，如果参数字符集不存在，则使用本地系统默认的字符编码 return StringCoding.encode(charsetName, value, 0, value.length); &#125; 综上，在这里再强调一下，因为修改了项目的编码方式，导致了本地系统的编码方式也变成了UTF-8，所以上述的实验都是基于IDE修改了工程项目编码方式的基础上 ByteBuffer与byte数组的互相转换在NIO中，一般都是使用ByteBuffer来当作字符缓冲，而有的时候我们只有byte[]数组，所以是需要它们之间进行相互转换的123456// ByteBuffer ----&gt; byte[]byte[] bytes = ByteBuffer.array();// byte[] ------&gt; ByteBufferbyte[] bytes = new byte[1024];ByteBuffer byteBuffer = ByteBuffer.wrap(bytes); So综上所述，再在这里总结一下： 本地JVM的编码方式是和本机OS默认的字符编码方式相关的，但是JVM的编码方式可以被修改 Java程序的默认字符集是Unicode，在程序中声明的String类型的编码方式是和JVM编码方式相关的 String.getBytes()方法默认的编码方式是JVM编码方式；同时还可以接收一个字符集名称当作参数，优先使用参数的字符集 因为Java代码使用的Unicode字符集，允许各编码方式之间转换，但不保证bit损失，所以String类型可以得到不同编码方式的byte数组，只要按照编码解码的方式获取字符串类型显示即可 文件的流通道是根据文件的编码方式决定的，所以不同编码方式的文件读写时要注意编码解码 ByteBuffer声明的buffer可以与byte数组之间进行转换，但要注意的是ByteBuffer的大小一定要足够大以承载下所有的byte数组 小总结搞清楚了这些甚是豁然开朗，其实很多时候中文的乱码问题根源就是编码方式与解码方式不一致，或者是不同编码方式之间转换时造成了bit损失。所以我们还是要注意规范化编码与解码方式，毕竟有的转换操作是不可逆的。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring 源码解析IoC]]></title>
      <url>%2F2017%2F08%2F05%2FSpring-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90IoC%2F</url>
      <content type="text"><![CDATA[前言能学习到这个，真心感谢大佬的总结，在此基础上我才能学习理解，这里粘出dalao的原文出处：Orz 拆分因为这个是更早建立的，当时没有想到这个部分深入到源码时会这么的多，后面只能分开来看，当然了，也就分开总结吧，这里给出链接 Spring IoC容器初始化Spring-IoC容器初始化 Spring IoC依赖注入Spring-IoC依赖注入 Spring IoC容器高级特性Spring IoC容器高级特性 感悟这个部分差不多花了好几个夜晚，从摸索着研究到开始上手，整理清除思路之后又做笔记写博客，感觉Spring的代码写的很棒，运用到了Java的特性非常之多以及如此精准，同时运用了大量的设计模式，确实是含金量很高的框架，值得我们去看看学学它的源码]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring IoC容器高级特性]]></title>
      <url>%2F2017%2F08%2F05%2FSpring-IoC%E5%AE%B9%E5%99%A8%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%2F</url>
      <content type="text"><![CDATA[IoC高级特性IoC容器对bean配置文件加载、解析、注册，实例化bean和依赖注入都是容器的基本功能，现在来看一看高级功能 lazy-init延迟加载设置了lazy-init=false属性（默认设置）后，IoC容器会进行Bean对象的预加载。 refresh()方法是IoC容器初始化开始的地方，在容器启动bean资源载入注册后，调用finifshBeanFactoryInitialization()方法准备进行bean的预实例化； 实际上，DefaultListableBeanFactory的preInstantiateSingletons()方法进行预实例化，这个Bean在单例模式下会有线程同步来保证数据一致性； 判断lazy-init的属性值，然后调用getBean()方法触发容器对bean实例化和依赖注入过程 FactoryBean和BeanFactory BeanFactory是bean工厂，Spring IoC最顶层的接口，作用是管理bean，即定位、配置对象、实例化和建立对象之间的依赖，getObject()方法由实现类调用，来创建bean实例化 FactoryBean工厂bean，作用是产生其它bean实例，提供工厂方法，返回其它bean实例，一般Spring容器担任工厂角色 BeanPostFactory后置处理器一个监听器，可以监听容器触发的bean声明周期事件；如果后置处理器向容器注册以后，容器管理的bean就具备了接收IoC容器时间回调的能力，可以为AOP的bean注册提供方便 @Autowire注解实现注解相当于一种声明，通过反射去取对应的值。一般使用该注解的对象都是我们自己定义的Bean对象，Spring在初始化这些对象时都是默认调用该类的无参构造方法。因此对于@Autowire注解的属性，Spring会解析出并调用相应的构造方法： 从构造方法缓存中查询其构造方法 若缓存不存在，则根据反射获取所有构造方法 遍历所有构造方法，查询器是否含有@Autowrie属性 判断Autowire注解中指定了required属性（判断是否强依赖），若存在required就使用默认构造方法 返回指定的构造方法 接下来是开始初始化，bean的自动装配发生在容器对bean的依赖注入过程中根据注解对属性注入 在第一次调用getBean()进行依赖注入时，完成依赖bean的初始化和注入 将依赖bean的属性引用设置到被依赖的bean属性上 将依赖bean的名称和被依赖bean的名称存储在IoC容器的集合中]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring-IoC依赖注入]]></title>
      <url>%2F2017%2F08%2F03%2FSpring-IoC%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5%2F</url>
      <content type="text"><![CDATA[IoC依赖注入发生的时间首先需要明确的是在IoC容器初始化之后，IoC容器已经开始管理Bean了，但是这时还不一定对管理的Bean进行了依赖注入 在配置文件中的标签设置了lazy-init=true，且第一次通过getBean()方法向IoC容器所要bean时，IoC容器触发依赖注入 当Bean配置文件的标签设置了lazy-init=false属性时，IoC容器在解析Bean定义时进行预实例化，触发依赖注入，也即是随着ApplicationContext文件的加载而触发依赖注入，这是默认情况 Bean的生命周期依赖注入发生的时间似乎可早可晚，这就不免让人思考一个问题，Spring中bean对象的生命周期问题，因为Spring的ApplicationContext容器在启动时会自动实例化所有singleton的Bean实例并缓存到容器中，那么这就开始了，接下来呢？ 其实这是一个好坑 依赖注入的步骤像上一篇IoC容器的初始化过程一样，涉及到了很多源码，这里只粘出总结出的步骤1234567891011121314151617IoC容器初始化完成 ↓AbstractBeanFactory通过getBean像IoC容器中获取bean，实际上是使用不同的模式来createBean：单例模式就是singleton的bean，原型模式就是不同的bean ↓createBeanInstance()生成bean的Java对象实例；populateBean()对bean属性的依赖关系进行注入 ↓bean对象使用工厂方法和自动装配特性来进行bean实例化： 参数匹配的构造方法或者相应的工厂方法进行实例化 默认无参的构造方法使用反射和CGLIB进行实例化，bean中的方法被覆盖了就使用反射，反之就是CGLIB ↓populateBean()方法对bean的属性开始注入 属性值类型不需要转换的直接调用set方法 属性值类型需要转换的，先解析在注入 ↓解析属性，各种List、Set、Map属性，解析成目标属性 ↓对于集合类型的属性，解析后注入属性；非集合类型的属性，使用大量反射和内省机制（缺省办法），使用get获取旧值，再使用set赋予新值 至此，完成了IoC依赖注入 一些细节再看很多博客时会注意到，大家对于IoC容器的初始化完成这个一点有不同的定义，有的是认为IoC容器加载解析注册完Bean配置之后就是完成了IoC容器的初始化，有的则认为还会包括接下来的Bean对象的依赖注入之后才是真正的完成了IoC容器的初始化从源码上来看，我个人认为这是有前提条件的，如果设置了延迟加载，Bean对象的依赖注入的代码与IoC加载解析注册的代码有明显的分为不同阶段；而网上大多会默认是没有设置延迟加载，因此认为Bean对象实例化是伴随着IoC容器实例化的。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MyCat多重规则哈希分片]]></title>
      <url>%2F2017%2F08%2F03%2FMyCat%E5%A4%9A%E9%87%8D%E8%A7%84%E5%88%99%E5%93%88%E5%B8%8C%E5%88%86%E7%89%87%2F</url>
      <content type="text"><![CDATA[MyCat分片规则MyCat自带的分片规则有很多种，而且支持自定义分片规则，灰常好用啊感觉巨佬整理的很细，容易理解 哈希取模分片：常见的分片方式，根据分片字段（一般是主键）的哈希值，再对分片个数取模运算，决定记录到哪个分片上；分片个数最好是2的n次方 路由约定分片：维护一个properties文件，针对不同的值设置不同的分片 范围路由约定分片：针对不同范围的值约定一个分片 哈希范围约定分片：分片字段值哈希取模后的范围约定分片 部分字段分片：截取某个字段的一部分作为分片依据，配合全局id生成器使用 多重规则分片：设置多种分片规则，比如一部分采用路由分片，一部分采用哈希范围分片 自定义分片规则MyCat支持自定义分片规则，自定义类需要继承AbstractPartitionAlgorithm类，然后实现calculate()或calculateRange()方法 源码这是看到了巨佬整理的博客，所幸自己也读懂了代码，忍不住自己也整理一下收获 AbstractPartitionAlgorithm源码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public abstract class AbstractPartitionAlgorithm implements RuleAlgorithm &#123; @Override public void init() &#123; &#125; /** * 返回所有被路由到的节点的编号 * 返回长度为0的数组表示所有节点都被路由（默认） * 返回null表示没有节点被路由到 */ @Override public Integer[] calculateRange(String beginValue, String endValue) &#123; return new Integer[0]; &#125; /** * 对于存储数据按顺序存放的字段做范围路由，可以使用这个函数 * @param algorithm * @param beginValue * @param endValue * @return */ public static Integer[] calculateSequenceRange(AbstractPartitionAlgorithm algorithm, String beginValue, String endValue) &#123; Integer begin = 0, end = 0; begin = algorithm.calculate(beginValue); end = algorithm.calculate(endValue); if(begin == null || end == null)&#123; return new Integer[0]; &#125; if (end &gt;= begin) &#123; int len = end-begin+1; Integer [] re = new Integer[len]; for(int i =0;i&lt;len;i++)&#123; re[i]=begin+i; &#125; return re; &#125;else&#123; return null; &#125; &#125;&#125; PartitionByMod源码 12345678910111213141516private int count;@Overridepublic void init() &#123;&#125;public void setCount(int count) &#123; this.count = count;&#125;@Overridepublic Integer calculate(String columnValue) &#123; BigInteger bigNum = new BigInteger(columnValue).abs(); // 简单的对分片个数取模 // x mod (2^n) = x&amp;(2^n-1) return (bigNum.mod(BigInteger.valueOf(count))).intValue();&#125; 不带范围约定的符合规则分片 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106/*** 首先实现不带范围约定的复合规则，即配置文件中为：* 北京=0，1，2,3,4* 上海=10,11*/public class PartitionByRouteHash extends AbstractPartitionAlgorithm implements RuleAlgorithm &#123; protected String routeFile; // 注意使用map存储分片规则对应关系 private Map&lt;String, List&lt;Integer&gt;&gt; routeNodeMap; protected static final String DEFAULT_NODE = "DEFAULT_NODE"; protected int keyStartIndex; protected int keyEndIndex; protected int valueStartIndex; protected int valueEndIndex; public void setKeyStartIndex(int keyStartIndex) &#123; this.keyStartIndex = keyStartIndex; &#125; public void setKeyEndIndex(int keyEndIndex) &#123; this.keyEndIndex = keyEndIndex; &#125; public void setValueStartIndex(int valueStartIndex) &#123; this.valueStartIndex = valueStartIndex; &#125; public void setValueEndIndex(int valueEndIndex) &#123; this.valueEndIndex = valueEndIndex; &#125; public void setRouteFile(String routeFile) &#123; this.routeFile = routeFile; &#125; @Override public void init() &#123; initialize(); &#125; @Override // 参数值一般就是等号的左值 public Integer calculate(String columnValue) &#123; String key = columnValue.substring(keyStartIndex,keyEndIndex); String value = columnValue.substring(valueStartIndex,valueEndIndex); List&lt;Integer&gt; nodes = routeNodeMap.get(key); if(nodes == null) nodes = routeNodeMap.get(DEFAULT_NODE); // 先进性哈希 BigInteger bigNum = new BigInteger(""+value.hashCode()); // 再对分片个数取模 return nodes.get((bigNum.mod(BigInteger.valueOf(nodes.size()))).intValue()); &#125; // 读取文件，创建哈希表保存对应关系 private void initialize() &#123; BufferedReader in = null; try &#123; InputStream fin = this.getClass().getClassLoader() .getResourceAsStream(routeFile); if (fin == null) &#123; throw new RuntimeException("can't find class resource file " + routeFile); &#125; // 准备逐行读取 in = new BufferedReader(new InputStreamReader(fin)); routeNodeMap = new HashMap&lt;String, List&lt;Integer&gt;&gt;(); for (String line = null; (line = in.readLine()) != null;) &#123; line = line.trim(); if (line.startsWith("#") || line.startsWith("//")) continue; int ind = line.indexOf('='); if (ind &lt; 0) continue; try &#123; String key = line.substring(0, ind).trim(); String value = line.substring(ind+1).trim(); String []nodes = value.split(","); // values是各个分片节点，采用整型队列存储 List&lt;Integer&gt; values = new ArrayList&lt;Integer&gt;(); for(int i = 0 ; i&lt; nodes.length ; i++)&#123; values.add(Integer.parseInt(nodes[i].trim())); &#125; // 将对应关系存储下来 routeNodeMap.put(key,values); &#125; catch (Exception e) &#123; System.out.println("something wrong in the route hash configuration!"); &#125; &#125; &#125; catch (Exception e) &#123; if (e instanceof RuntimeException) &#123; throw (RuntimeException) e; &#125; else &#123; throw new RuntimeException(e); &#125; &#125; finally &#123; try &#123; in.close(); &#125; catch (Exception e2) &#123; &#125; &#125; &#125;&#125; 带范围约定的复合规则分片 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119/*** 实现范围约定的复合规则* 上海（A00000-A100000）= 2,5,6* 北京（B00000-B100000）= 3,8,9*/public class PartitionByScalableRouteHash extends PartitionByRouteHash &#123; // 注意使用字段值的左半部分当作routeNodeMap的key，右半部分当作value的key，分片节点存储的队列当作value的value private Map&lt;String,Map&lt;String[],List&lt;Integer&gt;&gt;&gt; routeNodeMap; @Override public void init() &#123; initialize(); &#125; @Override public Integer calculate(String columnValue) &#123; String key = columnValue.substring(keyStartIndex,keyEndIndex); String value = columnValue.substring(valueStartIndex,valueEndIndex); Map&lt;String[],List&lt;Integer&gt;&gt; scaleMap = routeNodeMap.get(key); if(scaleMap==null)&#123; scaleMap = routeNodeMap.get(this.DEFAULT_NODE); &#125; String []ranges = new String[1]; // 遍历routerMap的value的key，取得范围的上下界的值，进行比对 for(String []range:scaleMap.keySet())&#123; if(range[0].equals(this.DEFAULT_NODE)) continue; if(range[0].compareTo(value)&lt;0&amp;&amp;range[1].compareTo(value)&gt;0) ranges = range; &#125; if(ranges.length==1) &#123; for(String []range:scaleMap.keySet())&#123; if(range[0].equals(this.DEFAULT_NODE))&#123; ranges = range; break; &#125; &#125; &#125; List&lt;Integer&gt; nodes = scaleMap.get(ranges); // 这里的value是传入的字段值中的范围，进行哈希 BigInteger bigNum = new BigInteger(""+value.hashCode()); // 将范围在进行取模 return nodes.get((bigNum.mod(BigInteger.valueOf(nodes.size()))).intValue()); &#125; private void initialize()&#123; BufferedReader in = null; try &#123; InputStream fin = this.getClass().getClassLoader() .getResourceAsStream(routeFile); if (fin == null) &#123; throw new RuntimeException("can't find class resource file " + routeFile); &#125; in = new BufferedReader(new InputStreamReader(fin)); routeNodeMap = new HashMap&lt;String, Map&lt;String[], List&lt;Integer&gt;&gt;&gt;(); for (String line = null; (line = in.readLine()) != null;) &#123; line = line.trim(); if (line.startsWith("#") || line.startsWith("//")) continue; int lb = line.indexOf('('),rb = line.indexOf(')'),mb = line.indexOf(':'); int ind = line.indexOf('='); if((lb!=-1&amp;&amp;rb!=-1&amp;&amp;mb!=-1)&amp;&amp;(mb&lt;lb||mb&gt;rb||lb&gt;rb||rb&gt;ind))&#123; throw new RuntimeException("Wrong format! Error use of (),:,=!"); &#125; if (ind &lt; 0) continue; try &#123; String key = line.substring(0, lb&lt;0?ind:lb).trim(); Map&lt;String[],List&lt;Integer&gt;&gt; scaleMap = routeNodeMap.get(key); if(scaleMap == null)&#123; scaleMap = new HashMap&lt;String[],List&lt;Integer&gt;&gt;(); routeNodeMap.put(key,scaleMap); &#125; String[] valueRange = new String[2]; if(lb!=-1&amp;&amp;rb!=-1&amp;&amp;mb!=-1) &#123; // 解析范围的上下届值，使用String数组存储 String minValue = line.substring(lb + 1, mb).trim(); String maxValue = line.substring(mb + 1, rb).trim(); if (minValue.length() != maxValue.length() || minValue.compareTo(maxValue) &gt;= 0) &#123; throw new RuntimeException("Wrong value range! "); &#125; valueRange[0] = minValue; valueRange[1] = maxValue; &#125; else &#123; valueRange[0] = this.DEFAULT_NODE; &#125; String value = line.substring(ind+1).trim(); String []nodes = value.split(","); List&lt;Integer&gt; node = new ArrayList&lt;Integer&gt;(); for(int i = 0 ; i&lt; nodes.length ; i++)&#123; node.add(Integer.parseInt(nodes[i].trim())); &#125; // 存储范围与分片节点的对应关系 scaleMap.put(valueRange,node); &#125; catch (Exception e) &#123; System.out.println("something wrong in the route hash configuration!"); &#125; &#125; &#125; catch (Exception e) &#123; if (e instanceof RuntimeException) &#123; throw (RuntimeException) e; &#125; else &#123; throw new RuntimeException(e); &#125; &#125; finally &#123; try &#123; in.close(); &#125; catch (Exception e2) &#123; &#125; &#125; &#125;&#125; 当然上述的两个方法是需要设置rule.xml配置文件的：12345678910111213&lt;tableRule name="scalable-route-hash"&gt; &lt;rule&gt; &lt;columns&gt;order_id&lt;/columns&gt; &lt;algorithm&gt;scalable-route-hash&lt;/algorithm&gt; &lt;/rule&gt; &lt;/tableRule&gt; &lt;function name="scalable-route-hash" class="org.opencloudb.route.function.PartitionByRouteHash"&gt; &lt;property name="routeFile"&gt;scalable-route-hash.txt&lt;/property&gt; &lt;property name="keyStartIndex"&gt;0&lt;/property&gt; &lt;property name="keyEndIndex"&gt;5&lt;/property&gt; &lt;property name="valueStartIndex"&gt;5&lt;/property&gt; &lt;property name="valueEndIndex"&gt;11&lt;/property&gt; &lt;/function&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring配置Mybatis执行原生SQL语句]]></title>
      <url>%2F2017%2F08%2F03%2FSpring%E9%85%8D%E7%BD%AEMybatis%E6%89%A7%E8%A1%8C%E5%8E%9F%E7%94%9FSQL%E8%AF%AD%E5%8F%A5%2F</url>
      <content type="text"><![CDATA[为什么要怎么做有这么一个应用场景：需要在Mybatis框架上进行多个连接池的配置，然后进行多种SQL语句的测试，因为有些SQL语句的结构比较复杂，有些会涉及到很多group by、join操作还有一些聚集函数的使用，同时数据量又较大。在这种情况下，常规的Mybatis面对对象进行操作的办法就不再试适用，查看Mybatis官方手册，提供了SQL构造器的办法也会有较的工作量，所以选择直接执行SQL语句（那为啥不用JDBC呢？笑） 遇到的坑凭我记忆中对Mybatis的用法，似乎并没有这么用的，去网上搜，居然真的存在这种用法，但是讲的大多含糊其辞，晕了一下午也没让我找到正确的做法（真心给跪） 将SQL当作SqlSession执行的参数：使用SqlSession的selectList()方法，传入的参数是SQL，当然需要在Bean的mapper xml配置文件中修改parameterType类型为String，同时因为String不支持getter和setter操作，手动封装一个包装类SQLAdapter 虽然看起来似乎可以，但是还是会存在坑的，即“SqlSession对象如何调用selectList()方法来传入SQL语句？”。一开始是直接12// sql 是原生SQL语句list = sqlSession.selectList("selectList",sql); 这样还是会提示String没有setter方法而报出异常 其实还有一个坑是关于在xml映射文件中 &lt;select&gt; 语句的返回值问题，有的查询语句是返回集合，而有的是返回整型值，直接设置resultType = &quot;XXX&quot;肯定是会报错的 第三个坑是解决了上述问题后报出的org.mybatis.spring.transaction.SpringManagedTransaction.getTimeout()异常，上网一搜，是mybatis-spring的版本问题 成功的做法试了整整一上午，反复踩坑跳坑，终于让我找到了一条正确的道路 按照上面提到的解决步骤先进行设置，重点放在执行查询的时候，sqlSession执行方法时传入的参数要注意不能是String类型的SQL，而需要是封装类SQLAdapter对象1list = sqlSession.selectList("selectList",new SQLAdapter(sql)); 即可解决第一个问题，可以执行部分语句 第二个问题说白了就是针对查询的返回值类型要有合适的“容器”来接收，不能是某个具体的类型，那么直接采用超类java.lang.Object来最为resultType的值 最后一个问题就好解决了，mybatis-spring的版本设置为3.4.0即可（原来是3.2.2），总之版本要高一些 一点想法其实自己学东西的时候肯定会遇到很多坑，有时比问题还坑的是网上的某些“指导”，总是会经历过心态崩溃的时候，只是希望自己不要成为误导别人的人ps：遇到不会的还是要多关注官方文档啊]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring-IoC容器初始化]]></title>
      <url>%2F2017%2F08%2F02%2FSpring-IoC%E5%AE%B9%E5%99%A8%E5%88%9D%E5%A7%8B%E5%8C%96%2F</url>
      <content type="text"><![CDATA[Spring Ioc容器IoC容器最主要是对Bean对象的创建和依赖管里注入，是整个Spring IoC功能的核心 基本结构Spring IoC结构很复杂，多个类继承实现关系混乱，但最基础的有三个 BeanFactory，对IoC容器的基本行为做出了定义 BeanDefinition，在IOC中可识别Bean资源文件的描述 BeanDefinitionReader，加载Bean资源文件 Ioc容器初始化过程这里举两个简单的例子 XmlBeanFactory容器一个较为低级的IoC容器，实现了最基本的功能12345678//根据Xml配置文件创建Resource资源对象，该对象中包含了BeanDefinition的信息 ClassPathResource resource =new ClassPathResource("application-context.xml");//创建DefaultListableBeanFactory DefaultListableBeanFactory factory =new DefaultListableBeanFactory();//创建XmlBeanDefinitionReader读取器，用于载入BeanDefinition。之所以需要BeanFactory作为参数，是因为会将读取的信息回调配置给factory XmlBeanDefinitionReader reader =new XmlBeanDefinitionReader(factory);//XmlBeanDefinitionReader执行载入BeanDefinition的方法，最后会完成Bean的载入和注册。完成后Bean就成功的放置到IOC容器当中，以后我们就可以从中取得Bean来使用 reader.loadBeanDefinitions(resource); ApplicationContext容器更为高级的IoC容器，除基本功能外，还支持信息源，可以实现国际化、访问资源和支持应用事件因具体涉及的源代码很多，原理也较难解释清除，故只列出最基本的流程 1234567891011121314151617181920212223ApplicationContext application = new FileSystemXmlApplicationContext(xmlPath); ↓父类AbastractRefreshableConfigApplicationContext为容器设置Bean资源加载器 ↓资源加载器resourceLoader被赋值，设置资源文件路径，然后对资源文件路径进行解析 ↓调用refresh()方法，这是IoC容器初始化的入口 ↓创建IoC容器，子类启动载入过程；ConfigurableListableBeanFactory beanFactory = obtainBeanFactory(); ↓创建DefaultListableBeanFactory对象，装载beanFactory对象loadBeanDefinitions(beanFactory) ↓新建Xml Bean读取器XmlBeanDefinitionReader对象，加载Bean资源文件 ↓resourceLoader.getSource(Location)获取资源 ↓加载Bean配置文件，对xml进行解析成Document对象 ↓按照Spring IoC识别的Bean规则在DefaultDefinitionDocumentReader中对Document对象进行解析 ↓解析文件的&lt;Import&gt;、&lt;Alias&gt;、&lt;property&gt;、&lt;List&gt;、&lt;Set&gt;等元素，Bean资源文件最终被解析成BeanDefinition对象，是资源原件在IoC中的映射 ↓BeanDefinition在IoC容器中进行注册 至此，Bean资源文件中配置的bean被解析成可以被IoC容器识别的对象且被注册管理起来，IoC容器可以进行索引、查询以及操作；被IoC容器管理起来后，也真正完成了IoC容器的初始化 注意IoC容器中的注册就是维护了一个HashMap，保存了BeanDefinition对象，方便了后续的管理 困了Orz从开始看到现在，四个多小时了，中间还喝了半瓶红葡萄酒，算是对Spring IoC容器的初始化了解了，明天再看AOP，现在真是困了…睡觉]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java线程池与数据库连接池区别]]></title>
      <url>%2F2017%2F08%2F02%2FJava%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%E5%8C%BA%E5%88%AB%2F</url>
      <content type="text"><![CDATA[线程池与数据库连接池的区别看到了MyCat参数设置时注意到了连接池的设置，突然发现好几个池化的概念，就顺手搜了一下，这里附上原文链接 线程池 其实线程池的原理很简单，类似于操作系统中的缓冲区的概念，它的流程如下：先启动若干数量的线程，并让这些线程都处于睡眠状态，当客户端有一个新请求时，就会唤醒线程池中的某一个睡眠线程，让它来处理客户端的这个请求，当处理完这个请求后，线程又处于睡眠状态。 当然为每一个请求单独的创建线程是很方便的，但是并发量很大时，如果为每一个请求都创建新的线程，那么耗费CPU时间和内存是很惊人的，同时反复创建、销毁线程带来的结果将是一场灾难 连接池 数据库连接是一种关键的有限的昂贵的资源，这一点在多用户的网页应用程序中体现得尤为突出。 一个数据库连接对象均对应一个物理数据库连接，每次操作都打开一个物理连接，使用完都关闭连接，这样造成系统的 性能低下。 数据库连接池的解决方案是在应用程序启动时建立足够的数据库连接，并讲这些连接组成一个连接池(简单说：在一个“池”里放了好多半成品的数据库联接对象)，由应用程序动态地对池中的连接进行申请、使用和释放。对于多于连接池中连接数的并发请求，应该在请求队列中排队等待。并且应用程序可以根据池中连接的使用率，动态增加或减少池中的连接数。连接池技术尽可能多地重用了消耗内存地资源，大大节省了内存，提高了服务器地服务效率，能够支持更多的客户服务。通过使用连接池，将大大提高程序运行效率，同时，我们可以通过其自身的管理机制来监视数据库连接的数量、使用情况等。1) 最小连接数是连接池一直保持的数据库连接，所以如果应用程序对数据库连接的使用量不大，将会有大量的数据库连接资源被浪费；2) 最大连接数是连接池能申请的最大连接数，如果数据库连接请求超过此数，后面的数据库连接请求将被加入到等待队列中，这会影响之后的数据库操作。 注意到还有一个概念是空闲连接，说的就是长连接时，有一个最大保持时间，目的是在达到一定时间不工作后对资源进行的回收 以我看来记得还有一个博客提到了对象池的概念，ta理解的数据路连接池就是保存了很多数据库连接对象的对象池。 我也觉得有道理，其实说白了，池化（缓冲）的作用就是在系统初始化时预先准备好资源，有请求时分配对象去使用，空闲时就进行回收但不销毁；这样做的目的是减少了对象反复创建、销毁所花费的时间，这在并发量很大的情况下是很吃资源的]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM内存分配与GC]]></title>
      <url>%2F2017%2F05%2F29%2FJVM%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E4%B8%8EGC%2F</url>
      <content type="text"><![CDATA[=_=本来这部分是不想写的，后面想想还是算了，毕竟是最早开始研究又算是相对了解的地方，这次就顺便总结一下看书的心得吧 JVM内存区域JVM提程序员管理了内存区域，免去了不少麻烦，但我们还是需要去了解的。这个内存区域分为了两大类五个区：方法区与Java堆、虚拟机栈与本地方法栈与程序计数器。具体的解释在很久之前研究String常量池的位置时已经有解释过了，不再赘述 JVM内存分配说到内存分配，还是得先了解一下JVM内存的分代管理，很久之前的一次面试有提到过这个分代机制，不过当时是懵逼的。 JVM的分代机制为了方便管理Java内存中的对象，JVM采用了分代管理的机制，即把整个内存区分为了年轻代、年老代和永久代 年轻代（young gen）：这里的Java对象存活时间非常短，属于经常发生GC的区域 年老代（old gen）：这里的对象是占用内存较大或者是存活时间很长的，一般这里发生的GC就是内存空间真的不足了 永久代（perm gen）：其实这部分内存空间就是JVM内存区域中的方法区，里面存放了类的加载信息、静态变量、常量以及代码等信息，这里一般不会发生GC（不代表没有），一般我们所说的GC是不考虑这个区域的 GC垃圾回收，这部分是JVM关键又重要的一个部分，虽然不需要我们直接参与管理，但一个Java程序员不懂垃圾回收是说不过去的，况且我们可以自由的设置JVM的GC来更好的提高程序运行的性能 什么时候开始GC如何开始GC是我刚开始了解GC到一定程度时考虑的东西，毕竟说是说当内存空间不足时JVM便自动开始GC并回收内存区域，但如何得知JVM内存空间够不够呢？查阅资料得知原来JVM对每个对象都有监视对象的监视器，用来监视对象的地址、大小以及使用情况，当该对象已死后，便会对该对象进行回收呐，总结一下发生GC的条件： 内存空间不足，又创建新对象并分配内存时 主动调用方法来控制GC 系统配置的某些参数改变，例如系统内存空间不足 主动触发GC的方法 对象调用finalize()方法，不保证该方法一定会执行，且最多执行一次 调用System.gc()方法，会触发Full GC Runtime.gc() 如何判断对象“已死”如何判断对象“已死”是一个值得说道的地方，正确判断对象是否存货是开始GC的关键。按照常规定义，我们认为一个没有引用指向的对象便是一个已经死去的对象。这里一般有两种方法来判断对象是否还有引用指向： 引用计数法：每有一个引用指向该对象，则其引用计数就加一 可达性分析：从GC Roots为起始点开始向下遍历，从引用链搜索引用对象（由JVM自己的监视器来负责） 主流的商用语言都采用可达性分析的方法来判断对象是否存活，其实这有一个相对详细的过程，JVM会在对象被会收前进行两次标记，两次标记完成后，该对象才是真正意义上的死亡。 两次标记与对象的复活JVM宣告一个对象真正死亡是需要对其进行两次标记的：如果对象经历过可达性分析后没有与GC Roots相连接的引用链，便会对其进行第一次标记，并根据其是否需要执行finalize()方法为条件进行筛选，如果需要执行便会调用finalize()方法，便会被放到一个F-Queue队列中，排队准备执行；如果不需要执行，直接进行第二次标记。 说到执行finalize()方法，这就是对象复活的最后一个机会，只要在执行的方法中重新建立一个引用关联即可。否则会被当作死亡对象进行第二次标记。但JVM不保证finalize()方法执行完毕，所以最好不用这个方法来进行GC，交给JVM管理就好 综上猜想，finalize()方法就是给该对象进行第二次标记并通知JVM回收 可作为GC Roots的对象阿里的一次面试问到了这里，但当时没有记清楚，所有没有答好 虚拟机栈（线程私有栈）中引用的对象 方法区中类的静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI(Java Native Interface)引用的对象 OopMap这个地方也是面试时提到了，但是当时把它跟GC Roots的知识点记混了，尴尬，小哥很nice的说那我们不说这个了（尬笑 HotSpot在使用GC Roots的理念时，采用了新的实现方式，因为原来的方式一是任务量大而是GC时间长，因而使用OopMap数据结构来记录栈上不同位置上对象的情况，其本身不存在与栈中，但是保有栈中对象的使用信息。JVM通过查询OopMap就可以得知对象的存活情况 GC使用的算法简单说就三种：标记-清理、复制算法和标记-整理算法 GC的回收器年轻代：Serial、ParNew和Parallel Scavenge年老代：Serial Old、Parallel Old和CMSJDK1.8正式投入商用的G1 GC的种类上面讲过的JVM内存分配机制只是泛泛而谈，算是一个引入，这里再结合内存分配机制与GC来看一下更为具体的内存分配机制 monitor GC：发生在新生代长的GC，（具体的GC过程日后再补 Full GC：发生在新生代和年老代中的GC，算是对整个活动内存的清理 发生Monitor GC的条件年轻代的GC是Monitor GC，针对Eden区满的时候触发，有时Monitor GC会直接转成Full GC，且Full GC的耗时会是Monitor GC的10倍以上。至于为什么会转成Full GC，是因为在Monitor GC时，会将存活较久的对象复制进年老代，如果复制前检测到年老代中剩余的空间不足以接受这些对象，则会触发Full GC来进行整个年轻代和年老代的GC。 发生Full GC的条件Full GC的触发条件较多： System.gc()的调用 年老代空间不足 永久代空间不足 CMS收集器出现promotion failed和concurrent mode failure异常 统计得到Monitor GC晋升到老年代的平均大小大于老年代剩余空间 堆中分配很大的对象，剩余空间不足 In The End处理完这个，JVM的垃圾回收机制和内存分配机制就差不多了，本来这个是很久之前就应该写的，现在才补上，主要是觉得blog中JVM这个板块的东西有点少且有一点细节记混了，趁着端午放假，正好把JVM剩下的类加载和并发也都处理处理吧]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java8新特性]]></title>
      <url>%2F2017%2F05%2F17%2FJava8%E6%96%B0%E7%89%B9%E6%80%A7%2F</url>
      <content type="text"><![CDATA[听说这是一次振奋人心的更新？看的某评价，Java8是自Java5以来一次重大的更新，很多细节的东西发生了改变或者是增加了新的特性。那看起来有点棒棒啊 滑稽啊滑稽关于Flag挖好新坑，函数式编程]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[小识字符编码]]></title>
      <url>%2F2017%2F05%2F17%2F%E5%B0%8F%E8%AF%86%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%2F</url>
      <content type="text"><![CDATA[罗罗嗦的复制粘贴以下内容全部来自百度百科 字符编码字符编码也称字集码，是把字符集中的字符编码为指定集合中某一对象（例如：比特模式、自然数序列、8位组或者电脉冲），以便文本在计算机中存储和通过通信网络的传递。常见的例子包括将拉丁字母表编码成摩斯电码和ASCII。其中，ASCII将字母、数字和其它符号编号，并用7比特的二进制来表示这个整数。通常会额外使用一个扩充的比特，以便于以1个字节的方式存储。 ASCII码：美国(国家)信息交换标准(代)码，一种使用7个或8个二进制位进行编码的方案，最多可以给256个字符(包括字母、数字、标点符号、控制字符及其他符号)分配(或指定)数值。西文字符集。基本的ASCII 字符集共有 128 个字符，其中有 96 个可打印字符，包括常用的字母、数字、标点符号等，另外还有 32 个控制字符。ASCII码使用7位2进制数表示一个字符，7位2进制数可以表示出2的7次方个字符，共128个字符。后期扩展的ASCII码使用8位二进制码，最高位为1。 MBCS码：为了扩充ASCII编码，以用于显示本国的语言，不同的国家和地区制定了不同的标准，由此产生了 GB2312, BIG5, JIS 等各自的编码标准。这些使用 2 个字节来代表一个字符的各种汉字延伸编码方式，称为 ANSI 编码，又称为”MBCS（Muilti-Bytes Charecter Set，多字节字符集）”。在简体中文系统下，ANSI 编码代表 GB2312 编码。 #GB2312码：ANSI编码里的一种，GB 2312是一个简体中文字符集，由6763个常用汉字和682个全角的非汉字字符组成。GB2312编码用两个字节(8位2进制)表示一个汉字，所以理论上最多可以表示256×256=65536个汉字。 GBK码：GBK即汉字内码扩展规范，K为扩展的汉语拼音中“扩”字的声母。GBK编码标准兼容GB2312，共收录汉字21003个、符号883个，并提供1894个造字码位，简、繁体字融于一库。GB2312码是中华人民共和国国家汉字信息交换用编码，全称《信息交换用汉字编码字符集——基本集》，采用双字节编码。 Unicode码：将世界上所有的符号都纳入其中，无论是英文、日文、还是中文等，大家都使用这个编码表，就不会出现编码不匹配现象。每个符号对应一个唯一的编码，乱码问题就不存在了。这就是Unicode编码。现在的规模可以容纳100多万个符号。有的Unicode编码衍生码使用四字节编码，很浪费资源。 UTF-8码：为了提高Unicode的编码效率，于是就出现了UTF-8编码。UTF-8可以根据不同的符号自动选择编码的长短。英文字母只需要一个字节即可。 Based64码：电子邮件系统中对于汉字的传输有时候会有乱码问题，为了能让邮件系统正常的收发邮件，需要把由其他编码存储的符号转换成ASCII码来传输，最后接收者也通过转换得到了没有乱码的邮件。比如，在一端发送GB2312编码－&gt;根据Base64规则－&gt;转换成ASCII码，接收端收到ASCII码－&gt;根据Base64规则－&gt;还原到GB2312编码。 PS：Java8正式引入Base64编码作为类库的标准]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[zpencheng]]></title>
      <url>%2F2017%2F05%2F15%2Fzpencheng%2F</url>
      <content type="text"><![CDATA[声明这是一篇关于PengCheng的自省，如果是误打误撞的就不用看了，基本是废话，以及一些醉话，或者是不知所言的胡言乱语 前言什么叫做“有趣”我想成为什么样的人？我想过什么样的生活？好吧我错了，我真的真的真的真的真的真的真的真的很想很想很想很想变的牛逼，变得引起别人的注意再装作丝毫不在意的样子去说这不是我想要的，但我现在真的真的真的真的真的很像变强，变的更强，变得更牛逼。至于在那之前说出的我不愿意我不想，都是lowB的我自作矫情而又自我安慰自欺欺人的吱呀。那是我的目标。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java中的throw和throws]]></title>
      <url>%2F2017%2F05%2F15%2FJava%E4%B8%AD%E7%9A%84throw%E5%92%8Cthrows%2F</url>
      <content type="text"><![CDATA[一些稀松平常的操作ok，一般每隔一段时间就会清清缓存，或者是拖的有点多了…… Java中的异常这是一个要开也能开的坑，但是不是很想操作，一般情况下会使用异常，找出异常并调试bug就行了，当然了有些场景是需要自己自定义适合场景的bug的，这就需要了解一些异常的基本知识 异常的出现多是一些外部原因，比如一些代码中没有注意到的会影响程序运行的细节 发生在程序运行期间，干扰了正常的指令流程。Java通 过API中Throwable类的众多子类描述各种不同的异常。因而，Java异常都是对象，是Throwable子类的实例，描述了出现在一段编码中的 错误条件。当条件生成时，错误将引发异常。 这里有Java异常类层次结构图：↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ 注意 Thorwable是类不是接口，当初有搞混 Error类是程序无法处理的错误，表示运行应用中出现了很严重的问题，不过一般是因为JVM内容出现了问题，这些问题是不需要try-catch的。一般出现了Error，JVM会自动停止运行，然后通过Error的子类来描述出错的类型，比如：OutOfMemoryError和NoClassDefFoundError Exception类是程序本身（JVM）可以处理的异常，有一个重要的子类RuntimeException及其子类，表示JVM常用操作引发的异常，比如：空值对象的应用、除数为0和数组越界 错误和异常的区别是：异常能被程序本身处理，错误是无法处理的 可查异常和不可查异常这里拓展Exception的一些知识，因为算是难重点易混点 可查异常：是编译器要求必须处理的异常，即必须使用try{}catch{}进行捕捉处理。除RuntimeException及其子类外，其它的Exception类及其子类都属于可查异常 不可查异常：包括运行时异常（及其子类）和错误，这里不要求使用try{}catch{}捕捉处理，当然可以选择捕捉处理 运行时异常和非运行时异常这算是另一种异常的分类方式 运行时异常：RuntimeException，顾名思义，运行时才会发生的异常，在敲代码阶段编译阶段是无法发现的，所以即便没有try{}catch{}捕捉处理也会编译通过，比如：空指针异常和数组下标越界 非运行时异常：也叫编译异常，这个就必须使用try{}catch{}来让程序自行捕捉处理了，否则会不予通过 抛出异常使用throw和throws来抛出异常 捕获异常其实不过异常有两种，一种是自己编程处理，一种是交给JVM来处理 使用try{}catch{}来捕获异常 直接使用throws来不断向上抛出异常，直到抛给JVM执行 throw其实是从网上瞄来的（滑稽语法是throw(异常对象)，一般用于方法体中，抛出特定类型的异常 throws感觉diaodiao的，这个用的做多语法是public void function(var) throws &lt;异常类&gt;，一般跟在方法名的声明后面，直接抛出异常类，然后把异常处理交给上层调用它的程序处理 它们的区别卧槽我本来只是看到了两者什么区别，结果又扯了别的。说到区别，一个常用一个基本不用算不算区别（滑稽 throws出现在方法函数头，而throw出现在方法体中 throws表示出现异常的一种可能，实际并不一定会出现异常；而throw则是抛出异常，只要是运行到了这里，就一定会抛出异常 两者都是消极处理异常的方式，只是做到了抛出或肯能抛出异常，真正对异常进行处理还是在上层调用的地方 其实这里有更多详细的内容，随用随取还有这些，感谢前辈 一种熟悉的节奏？不知道什么时候起，已经想把自己看到学到的东西通过某种方式记录下来了，或许是自己的记性越来越不好了，又或许真的是已经变成了一种习惯。 没有遇到很多像自己一样喜欢搞一搞Java很底层很细节的东西，（或许自己本身也是被外在事物所影响，但现在确实真心的想搞清楚）每次看到一些很细枝末节的东西而自己又不知道，就会有莫名的兴奋感，细细研究左右对比仔细斟酌。良久，一句“原来是这样”，痛快的拍一下桌子，随口吐槽一句，然后再嚣张的把博文传到网上，整个过程是这么熟悉而又畅快。日后装作随意的点开一看，点击的人数比上次又多了几个，顺便暗爽原来我当时写出这样的东西，但这是发自内心的开心。 啧，话又多了，自己也不明所以。话说，我要去洗袜子了 PS：其实每次问题的出发点都是一个小小的线头，怪我太贪心想要它后面的毛线球？]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Spring学习笔记-基础]]></title>
      <url>%2F2017%2F05%2F08%2FSpring%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%9F%BA%E7%A1%80%2F</url>
      <content type="text"><![CDATA[Spring介绍spring是一个开源的轻量级JavaEE框架，使用分层架构，主要部分是面向切面编程（AOP）和控制反转（IOC）容器代码的实现。提高复用性和松耦合，具有动态可扩展性 Eclipse和IDEA的项目构建Eclipse普遍比Idea要好配置的多 Eclipse 新建一个Project，都可以 导入外部的Jar包，组成新的Libraries 如果是Java Web项目还需要把所有的Jar包复制进web/WEB-INF/lib目录下 在src目录下创建applicationContext.xml文件 Idea 创建Java项目，从右边栏中选择Spring4，然后勾上对号 在下方选择Use Libraries，然后选择所需要的Jar包导入成Libraries 一路自由设置 进入项目后在src目录下创建applicationContext.xml文件 为项目配置合适的Artifact、Facets和Modules，就是选选文件配置路径什么的，如果哪里不对或缺失，右下方会有提示，点击fixed就会自动调整了 配置文件的组装一般来说，xml文件内容配置成这样就通用了1234567891011121314151617181920212223&lt;?xmlversion="1.0"encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:task="http://www.springframework.org/schema/task" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.1.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-3.1.xsd http://www.springframework.org/schema/task http://www.springframework.org/schema/task/spring-task-3.1.xsd"&gt; &lt;beans&gt; IOC/DIIOC：控制反转，有的时候也称为DI，也即依赖注入。可以这样理解： IOC容器就是为了管理Bean，创建Bean的一个内存区，在这个内存区中可以将操作Bean的代码以面向接口的方式进行开发。这样基于接口的多态性，程序结构的分层就更加灵活化，维护和扩展也很方便。IOC概念从技术上来讲就是将接口和实现相分离 IOC容器通过IOC容器可以完全管理JavaBean，包括创建、销毁，还可以对数据库的JavaBean进行自动化的事务处理，还支持一些企业级的应用。Spring的IOC容器完全脱离了平台，用最简单的JavaBean技术实现接口与实现的分离，并对组件的调配提供很好的支持 下面开始操作： 先准备一个JavaBean1234567891011121314151617public class CategoryBean &#123; private int id; private String name; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 注意经过实验发现，如果变量的getter和setter方法命名不规范，在程序运行时会出错。所以建议遵守set+Variale_name和get+Variable_name来命名getter和setter方法 再在applicationContext.xml文件中添加Bean配置12345&lt;beans ....&gt; &lt;bean name="cate" class="pojo.Category"&gt; &lt;property name="name" value="hellosocra" /&gt; &lt;/bean&gt;&lt;/beans&gt; 这里需要讲解一下配置的细节： 首先是标签中的name属性，这里就是创建一个名为cate的CategoryBean对象 xml配置文件中标签的id属性和name属性基本上没有什么区别，但是使用id会更加符合规范，因为xml中id要求是唯一的 class属性的值就是CategoryBean.java的路径，要加上包名 标签是为了给对象cate中的属性赋值的，这里会自动调用变量的getter和setter方法进行赋值，如果命名不规范，就无法赋值 name对应着cate的属性名，value就是赋值，本例赋予了name属性的值是hellosocra 中还可以使用ref来给属性值进行链接，然后使用链接处的值，这也是注入值的过程 使用注入的对象既然已经添加了注入对象的配置，现在看看如何使用注入的对象12345678910111213public class TestSpring &#123; public static void main(String[] args) &#123; // 1.必备的语句，可以定义为全局变量 ApplicationContext context = new ClassPathXmlApplicationContext( new String[] &#123; "applicationContext.xml" &#125;); // 2.开始使用IOC的getBean()方法来获取对象，但要主要强制类型转换 Category cate = (Category) context.getBean("cate"); // 3.使用Bean对象的方法 System.out.println(cate.getName()); &#125;&#125; 注解方式配置IOC如同在学习Servlet时使用注解配置一样，这里也可使用注解配置，有下面两种 针对“注入对象行为”的注解下面说的这种方式都是主要针对其中一个JavaBean是另一个JavaBean的属性时的注入 注释之前对对象的属性的注入的配置（配置对象是注入，给对象的属性赋值同样是注入） 添加&lt;context:annotation-config/&gt;表示spring要采用注解的方式进行配置 在要注入对象的对应属性前加上@Autowired注解，或者在对应属性的setter方法前加上@Autowired注解 在要注入对象中的属性（另外的JavaBean充当该bean的属性）前加上@Resource(xxx=xxx)注解，举个例子123456789101112class ABean&#123; String name ; int id; // ....getter和setter方法&#125;class BBean&#123; @Resource(name="socra",id=5) A a; // A作为B的属性 int no; // ....getter和setter方法&#125; 针对“Bean”的注解同样的，下面说的这种方式都是主要针对其中一个JavaBean是另一个JavaBean的属性时的注入 在xml文件中把标签中所有的标签都注释掉 添加&lt;context:componment-scan base-backage=&quot;JavaBean所在的包以及Bean名&quot;&gt;，表示spring所需要的Bean都在该路径下 再在该包下所有的Bean类定义之前加上@Compent(&quot;name&quot;)，表名该类是Bean，name是要被注入的该Bean类的对象名 若有一个类是另一个类的属性，则在该属性前加上@Autowired注解 其余的属性可以自由赋值 IOC原理传统的创建对象的方式：通过new关键字来创建一个对象IOC方式：对象的声明周期由Spring来管理，直接从Spring那里获取一个对对象。IOC是反转控制，意即本来对象的控制权在使用者手里，现在反过来交给了Spring 打个比喻：传统方式：相当于你自己去菜市场new 了一直鸡，但是是生鸡，要自己拔毛，去内脏，再上花椒，酱油，烤制，经过各种工序之后，才可以食用。IOC：相当于去馆子(Spring)点了一直 鸡，交到你手上的时候，已经五味俱全，你就只管吃就行了。 解释的生动传神，（滑稽 AOPAOP：面向切面编程，意即面向一小段代码编程。AOP把功能分为核心功能和周边功能，而周边功能在Spring的AOP思想里就被定义为切面Aspect。这种能够选择性的，低耦合的把切面和核心业务功能结合在一起的编程思想，就叫做切面编程。所谓AOP思想就是两种功能分别独立开发，然后再“编织”在一起 AOP可以在不改变原始代码的基础上做一些功能性的增强 需要额外的Jar包：aspect.jar和aopliance.jar 准备一个核心业务Bean和切面辅助Bean12345678/** * 作为核心业务Bean */public class ProductService&#123; public void dosomeService()&#123; System.out.println("dosomeService"); &#125; &#125; 1234567891011121314151617/** * 作为切面辅助Bean */public class LoggerAspect &#123; public Object log(ProceedingJoinPoint joinPoint)&#123; Object obj = null; System.out.println("start log: " + joinPoint.getSignature().getName()); try &#123; obj = joinPoint.proceed();// 继续执行，本例指执行dosomeService() &#125; catch (Throwable e) &#123; e.printStackTrace(); &#125; System.out.println("end log: " + joinPoint.getSignature().getName()); return obj; &#125; &#125; 添加配置1234567891011121314151617&lt;beans ....&gt; &lt;!-- 1.声明核心业务对象 --&gt; &lt;bean id="s" class="service.ProductService"&gt;&lt;/bean&gt; &lt;!-- 2.声明辅助日志切面 --&gt; &lt;bean id="loggerAspect" class="aspect.LoggerAspect"&gt;&lt;/bean&gt; &lt;!-- 5.通过aop:config把业务对象与辅助功能编制在一起 --&gt; &lt;aop:config&gt; &lt;!-- 3.指定核心业务功能 --&gt; &lt;aop:pointcut id="loggerCutpoint" expression= "execution(* service.ProductService.*(..))"/&gt; &lt;!-- 4.指定辅助功能 --&gt; &lt;aop:aspect id="logAspect" ref="loggerAspect"&gt; &lt;aop:around pointcut-ref="loggerCutpoint" method="log"/&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt;&lt;/beans&gt; 首先要规定好核心业务Bean还有切面辅助Bean，设置好它们的对象名以及路径 标签有指定好核心业务和切面辅助入口，id属性都是对象名 中的expression属性的一般值为execution(* package_name.Bean_name.*(..))，表示核心业务Bean中的方法入口（核心业务中可以不止一个方法） 标签中id被注入了值，pointcut-ref属性指定了辅助切面辅助的对象，method是调用辅助切面中的辅助方法 至此已经设置好了切面辅助，当从上到下，先执行核心业务功能后执行辅助业务 使用因为使用AOP，使用时和没有加入切面时的步骤是一样的，正因为如此也体现了AOP的优越特性123456789101112public class TestAspect &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub ApplicationContext apc = new ClassPathXmlApplicationContext("applicationContext.xml"); ProductService s = (ProductService)apc.getBean("s"); s.dosomeService(); &#125;&#125; AOP更高级的用法本来是想直接在这次写上的，但是，还是下次和IOC的高级用法写在一起吧，算偷个懒挖个坑。哦，当然了，AOP的注释写法也下次再写好了233333 久违了准备了很久的JavaEE学习，现在终于提上了日程，随便也要把之前遗漏的Servlet和Jsp准备准备填坑了 呐现在挖坑：Servlet学习总结笔记、Jsp总结笔记、Spring更为高级的用法etc PS：首先还是总结这几个框架任意组合的配置方法，idea配置起来真的麻烦啊….F__k]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java泛型详解]]></title>
      <url>%2F2017%2F05%2F07%2FJava%E6%B3%9B%E5%9E%8B%E8%AF%A6%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[为什么要来再详究一遍泛型当初学习Java时并没有觉得这个有多重要，又不像C++，我有现成的集合框架可以使用，我管你泛型干吗，（滑稽现在慢慢的学到了JavaEE的一些知识，所起来，框架中的原理知识除了有Java的反射机制，还大量的用到了泛型的知识，随便点开一个方法的源码，很容易发现有泛型的痕迹。但是仔细一想，这点似乎并没有搞清楚，所以 正文RT，本次讨论的主要目标，泛型。为了节省时间，一下的研究主要内容来自先驱者的博文指导，所以可以算是转载，侵删 为什么需要泛型这个探讨的节奏深得我心啊，先说是不是，再问为什么（滑稽先看一段代码：12345678910111213141516171819/** * 主要是为了深入了解学习 泛型 * NewPrint类是写的简化输出的工具类 */public class TestGeneric extends NewPrint&#123; List list = new ArrayList(); @Test public void test()&#123; list.add("hello"); list.add(100); for(int i=0;i&lt;list.size();i++)&#123; // 再取第二个值时会出异常 java.lang.ClassCastException String name = (String)list.get(i); println("name: "+name); &#125; &#125;&#125; 测试运行时会报出异常java.lang.ClassCastException，这是类型不匹配的异常。List默认的类型是Object类型的，什么类型的对象都可以往里面装。装入时是Integer类型的然后强制转为String类型自然会出错从上面可以看出两个问题： 当一个对象放入集合中时，集合并不会记住这个对象本来的类型；当该对象从集合中取出时，它的编译类型就变成了Object类型，但运行时还是会按照其本来的类型运算（这就是为什么编译时不会报错，允许强制转换，运行时却出异常的原因） 当从一个集合中取出对象时，因为可能不知道其真实类型而去强制转换，这是很容易触发java.lang.ClassCastException 所以就有了这么 一个需求：如何可以使集合“记住”元素的类型，并在运行时不会出现java.lang.ClassCastException的异常呢？ 什么是泛型 泛型，即“参数化类型”。一提到参数，最熟悉的就是定义方法时有形参，然后调用此方法时传递实参。那么参数化类型怎么理解呢？顾名思义，就是将类型由原来的具体的类型参数化，类似于方法中的变量参数，此时类型也定义成参数形式（可以称之为类型形参），然后在使用/调用时传入具体的类型（类型实参）。 简单说就是将一个类型当作参数传入另一个接口/类/方法的参数 于是将上面代码改为：1234567891011121314151617public class TestGeneric extends NewPrint&#123; List&lt;String&gt; newl = new ArrayList&lt;String&gt;(); @Test public void testNewList()&#123; newl.add("hello"); // 这里会直接拒绝加入Integer类型的元素 //newl.add(100); newl.add("scora"); for(int i=0;i&lt;newl.size();i++)&#123; // 再取第二个值时会出异常 java.lang.ClassCastException String name = newl.get(i); println("name: "+name); &#125; &#125;&#125; 采用泛型写法后，当想插入非String类型的对象时就会直接提示出错，同时当从集合中取值时也没有必要强制类型转换。可以得知在List中，String是类型实参，也就是说，相应的List接口中肯定含有类型形参。且get()方法的返回结果也直接是此形参类型（也就是对应的传入的类型实参）。看一看List的源码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public interface List&lt;E&gt; extends Collection&lt;E&gt; &#123; int size(); boolean isEmpty(); boolean contains(Object o); Iterator&lt;E&gt; iterator(); Object[] toArray(); &lt;T&gt; T[] toArray(T[] a); boolean add(E e); boolean remove(Object o); boolean containsAll(Collection&lt;?&gt; c); boolean addAll(Collection&lt;? extends E&gt; c); boolean addAll(int index, Collection&lt;? extends E&gt; c); boolean removeAll(Collection&lt;?&gt; c); boolean retainAll(Collection&lt;?&gt; c); void clear(); boolean equals(Object o); int hashCode(); E get(int index); E set(int index, E element); void add(int index, E element); E remove(int index); int indexOf(Object o); int lastIndexOf(Object o); ListIterator&lt;E&gt; listIterator(); ListIterator&lt;E&gt; listIterator(int index); List&lt;E&gt; subList(int fromIndex, int toIndex);&#125; 在List接口中采用泛型化定义之后，中的E表示类型形参，可以接收具体的类型实参，并且此接口定义中，凡是出现E的地方均表示相同的接受自外部的类型实参。注意一下这两个常用的方法： boolean add(E e); E get(int index); 第一个方法一定需要类型的参数，第二个方法一定会返回一个类型的对象，这也就解释了上面为什么add加入一个非String类型的值会直接提示出错，为什么从集合中取值不再需要强制类型转换。当然了，这只是List接口的定义，ArrayList实现类既然实现了List，那么一定会重写add()方法和get()方法，所以其也是需要类型的参数的 使用泛型的好处谈完了什么是泛型，按照我的节奏，我一般都会去想一想使用它的好处都有什么 类型安全：在使用时对一个对象进行了限制，只有约定类型的对象才能继续，编译器在编译时期也可以进行类型检查 避免强制类型转换：因为前面已经约束了类型，所以在使用时就已知了类型，便省去了类型转换的过程，使得代码更加可读，也减少了出错的机会 潜在的性能收益：泛型为较大的优化带来可能。在泛型的初始实现中，编译器将强制类型转换（没有泛型的话，程序员会指定这些强制类型转换）插入生成的字节码中。由于泛型的实现方式，支持泛型（几乎）不需要 JVM 或类文件更改。 泛型类、泛型接口和泛型方法大概知晓了泛型的知识，来看看我们如何使用泛型： 泛型类使用示例：1234567891011121314151617181920212223242526class A&lt;E&gt;&#123; private E e; public A()&#123; &#125; public A(E e)&#123; this.e = e; &#125; public void setE(E e)&#123; this.e = e; &#125; public E getE()&#123; return e; &#125;&#125;public class MyGenericityClass extends NewPrint&#123; A&lt;String&gt; a = new A&lt;String&gt;("socra"); @Test public void testA()&#123; println(a.getE()); &#125;&#125; 对于不同传入的类型实参，生成的相应对象实例的类型是不是一样的呢？123456789@Testpublic void testGenericityType()&#123; A&lt;String&gt; str = new A&lt;String&gt;("socra"); A&lt;Integer&gt; no = new A&lt;Integer&gt;(10); println(str.getClass()); // class Genericity.A println(no.getClass()); // class Genericity.A System.out.println(str.getClass()==no.getClass()); // true&#125; 输出结果竟不是预料的，原以为在编译时，编译器会将所有的泛型擦除变成其真实的类型，但现在看来似乎不是这样 由此，我们发现，在使用泛型类时，虽然传入了不同的泛型实参，但并没有真正意义上生成不同的类型，传入不同泛型实参的泛型类在内存上只有一个，即还是原来的最基本的类型（本实例中为Box），当然，在逻辑上我们可以理解成多个不同的泛型类型。究其原因，在于Java中的泛型这一概念提出的目的，导致其只是作用于代码编译阶段，在编译过程中，对于正确检验泛型结果后，会将泛型的相关信息擦除，也就是说，成功编译过后的class文件中是不包含任何泛型信息的。泛型信息不会进入到运行时阶段。对此总结成一句话：泛型类型在逻辑上看以看成是多个不同的类型，实际上都是相同的基本类型。 很奇怪，不是吗？（《Think in Java》P372之后的章节有详述 泛型中“擦除”一个很玄学的东西：Java泛型中的具体类型信息在运行时都被擦除了，而被当作泛型类型的对象去使用。（在泛型代码内部是无法获取任何有关泛型参数类型的信息） 在基于擦除的实现中，泛型类型被当作第二类类型被处理（没有具体化），即不能在某些重要的上下文中使用的类型。泛型类型只有在静态类型检查期间才会出现，在此之后，程序中的所有泛型类型都将被擦除，替换为它们的非泛型上界。例如，List这样的类型注解被擦除为List，而普通的类型变量类型在未指定边界的情况下将被擦除为Object 那么问题来了，我们是如何得知泛型中参数类型的呢？毕竟我们在运行时还需要检查其类性呢首先在编写代码时进行检查就容易实现了，编辑器自动检测泛型类型是否一致，下面来看看编译运行时的检测办法：首先是一点不使用泛型的代码：12345678910111213141516171819202122232425public class Test2&#123; static class A&#123; private Object obj; public A()&#123; &#125; public A(Object obj)&#123; this.obj = obj; &#125; public void setObject(Object obj)&#123; this.obj = obj; &#125; public Object getObject()&#123; return obj; &#125; &#125; public static void main(String[] args)&#123; A a = new A(); a.setObject("socra"); String str = (String)a.getObject();&#125;&#125; 反编译后查看其字节码发现：注意红线画到的地方 接下来看同样操作使用泛型的写法：1234567891011121314151617181920212223242526public class Test&#123; static class A&lt;E&gt;&#123; private E e; public A()&#123; &#125; public A(E e)&#123; this.e = e; &#125; public void setE(E e)&#123; this.e = e; &#125; public E getE()&#123; return e; &#125; &#125; public static void main(String[] args)&#123; A&lt;String&gt; a = new A&lt;String&gt;(); a.setE("socra"); String str = a.getE(); &#125;&#125; 同样反编译查看字节码可以发现：可以看到两者的字节码是一样的，然后注意到checkcast这个部分，这是检查类型的语句，事实上这才是关键所在。编译时擦除了泛型的参数类型信息，在编译时在边界地方开始检查类型，所谓边界就是对象进入和离开的地方。 在实例一中，会在强制转型的地方开始检测参数类型； 在实例二中，会在调用getObject()方法处检查参数类型 综上，我们知道为什么泛型可以知道参数类型信息了（先擦除后检查类型，毕竟泛型的主要目的之一就是希望将错误检测移入到编译期 泛型中的边界边界可以在泛型的参数类型上设置限制条件，例如class A&lt;T extends B&gt;，表示的意思就是参数类型必须是B类型或者是继承自B的子类。 泛型接口看过了上面泛型类的例子，就知道泛型接口就是接口有参数类型1234567891011121314151617181920public interface B&lt;E&gt;&#123; public void setE(E e); public E getE();&#125;class NewB implements B&lt;String&gt;&#123; // 泛型接口中的泛型对象定义在实现类中 String name ; @Override public void setE(String str)&#123; this.name = str; &#125; @Override public String getE()&#123; return name; &#125;&#125; 注意接口声明的小细节 接口的默认访问修饰符是protected 接口中的属性只能是static或final修饰的已知类型的对象，同时接口中不允许声明构造方法 泛型对象需要在实现类中定义 泛型方法关注到这个是因为学到了hibernate中的某一个方法，看一看Java中的泛型方法。1234567891011121314151617/** * 泛型方法 * &lt;T&gt; 用来声明该方法为泛型方法 * @param t 参数类型对象 * @return */public static &lt;T&gt; T display(T t)&#123; println("hello，这里是泛型方法"); return t;&#125;@Testpublic void testDisplay()&#123; String name = "socra"; String name2 = display(name); println(name2);&#125; 这里还有dalao提供的进阶版泛型方法，当然了，框架中使用的泛型方法就是这种类型：123456789101112/** * 基于反射的泛型方法 * Class&lt;T&gt; 声明泛型的T的具体类型 * @param t 是泛型T类的需要被代理的对象 * @return 实例化的代理对象 * @throws IllegalAccessException 安全权限异常 * @throws InstantiationException 实例化异常 */public &lt;T&gt; T getObject(Class&lt;T&gt; t) throws InstantiationException, IllegalAccessException&#123; T newt = t.newInstance(); // 基于反射创建对象 return newt;&#125; 类型通配符从上面的例子中，可以得知A和A其实还是一种类型，那么能否将这两种类型看作是与A类型有关系的父子类型呢？这里就需要有一个引用类型，用来在逻辑上表示形如A和A父类的引用类型。这就引出了我们的关注焦点——类型统配符。 神奇的 ‘?’java中类型通配符一般是使用?代替具体的类型实参。注意了，此处是类型实参，而不是类型形参！且A&lt;?&gt;在逻辑上是A、A…等所有A&lt;具体类型实参&gt;的父类。12345678910111213public static void aPrintln(A&lt;?&gt; a)&#123; println(a.getE());&#125;@Test// 用以测试通配符public void testWildcard()&#123; A&lt;String&gt; str = new A&lt;String&gt;("socra"); A&lt;Integer&gt; no = new A&lt;Integer&gt;(10); aPrintln(str); // socra aPrintln(no); // 10&#125; 可以看到将A&lt;?&gt;当作A和A的父类然后直接传入参数，利用多态特性完成输出 通配符的上下界其实这是泛型边界的定义，上文也有说到，但边界也可用于通配符中 类型通配符上界：&lt;? extends T&gt;，必须是T类或者其子类 类型通配符下界：&lt;? super E&gt;，必须是E类或者是E类的父类 泛型数组？不存在的，Java中没有泛型数组这么一说，所有想用到泛型数组的地方都可以使用List&lt;E&gt;来代替 话尾一不小心怎么研究了这么多，前前后后加上翻书查资料加上做做小实验，4个小时+应该是有的，不敢说翻了个底朝天，掌握大部分应该是有的。其实很喜欢这种状态。当然了，对Java掌握的越深越好啊 :-)，还是那句话，先狗后人]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java变量的默认初始化]]></title>
      <url>%2F2017%2F05%2F07%2FJava%E5%8F%98%E9%87%8F%E7%9A%84%E9%BB%98%E8%AE%A4%E5%88%9D%E5%A7%8B%E5%8C%96%2F</url>
      <content type="text"><![CDATA[变量的默认初始化Java是会为类的成员变量提供默认初始化的，但是又听说局部变量不会提供默认的初始化，是这样吗？1234567891011121314151617181920212223242526272829public class TestVariable &#123; public int id; public String name; public char c; public byte by; public float f; public double d; public boolean bo; // 再次说明了局部变量只能有final修饰符，static都不行 @Test public void testV()&#123; int no; final int no2; System.out.println(id); // 0 System.out.println(name); // null System.out.println(c); // 空字符 System.out.println(by); // 0 System.out.println(f); // 0.0 System.out.println(d); // 0.0 System.out.println(bo); // false // 局部变量没有初始化，编译就报错// System.out.println(no);// System.out.println(no2); &#125; &#125; 结果男默女泪，编译时就出错了 类的成员属性的默认初始化结论是会为类的普通属性成员初始化 基本数据类型: int: 0 char: 空字符 byte: 0 float: 0.0 double: 0.0 short: 0 long：0 boolean: false 对象类型String: nullOther Object: null 局部成员的默认初始化局部变量并不会默认的初始化，而是在编译时就直接报错！！！ 局部变量的修饰符局部变量不允许使用修饰符，只能使用final,static都不行]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java内部类探讨]]></title>
      <url>%2F2017%2F05%2F07%2FJava%E5%86%85%E9%83%A8%E7%B1%BB%E6%8E%A2%E8%AE%A8%2F</url>
      <content type="text"><![CDATA[默认的访问修饰符最初的发现是遇到了一个疑问，Java中类、接口、内部类、抽象类中属性方法的默认访问修饰符是什么？稍微查了查资料 普通类默认的访问修饰符是：default，也即包内友好 接口中的属性的默认是public static final ，方法是public abstract 内部类默认的访问修饰符是：public，只是要依附与外围类 抽象类默认的访问修饰符是：default 注意Java中外围类、接口、抽象类的访问修饰符只能是public和default 成员内部类访问修饰权限的测试这里还可以看一看如何实例化成员内部类，（滑稽 前期准备 包InPackage中有一个OutClass，里面有一个内部类InClass作为成员变量 同一个包下有一个测试类InPackage_OutClass 不在同一个包下有一个测试类OutPackage_OutClass 成员内部类的实例化方法1234567OutClass.InClass in = new OutClass.InClass(); //只有在内部类中的外围类中可以使用// 1.通用OutClass.InClass in2 = new OutClass().new InClass();// 2.通用OutClass out = new OutClass();OutClass.InClass in3 = out.new InClass(); 实验测试的方法就是看能否实例化成员内部类对象 首先是直接在外围类中测试 123456789101112131415161718192021222324252627282930313233343536/** * public &gt; protected &gt; default &gt; private * private 不能修饰外部类 * protected 不能修饰外部类 */public class OutClass &#123; // 作为成员内部类,内部类拥有其外围类的所有成员的访问权 // 不加修饰符的情况下，其修饰符是 default public class InClass&#123; //public static int id; // static变量违法 // 内部类不能有static方法，因为内部类必须依赖与外部类存在 public void print()&#123; System.out.println("this inner class"); &#125; &#125; @Test public void testInClass()&#123; // 1.成员内部类的一种初始化方法 InClass in = new InClass(); in.print(); // 2.成员内部类的另一种初始化方法 OutClass.InClass in2 = new OutClass().new InClass(); in2.print(); // 3.使用外部类绑定来初始化 OutClass out = new OutClass(); OutClass.InClass in3 = out.new InClass(); // 4.当内部类是static修饰时可以使用这个初始化方式 //InClass in4 = new OutClass.InClass(); &#125;&#125; 接着是“同包不同类”中实验 123456789101112131415161718192021222324/** * 该类旨在测试同一个包下，是否可以访问内部类 * * 所以访问权限是，只有依附与外部类，内部类是可以访问的；但无法直接访问，即便是public也不行 */public class InPackage_OutClass &#123; @Test public void testInClass()&#123; OutClass out = new OutClass(); // 1.同一个包的情况下，可以访问内部类 OutClass.InClass in = new OutClass().new InClass(); // 不使用.new便无法初始化对象 // OutClass.InClass in2 = new OutClass.InClass(); // 在内部类的外围类中可以使用该初始化方法 // 2.使用外部类对象绑定初始化内部类 OutClass.InClass in3 = out.new InClass(); // 在同一个包的情况下，可以直接导入，但原理还是与上面一致 InClass in4 = out.new InClass(); &#125;&#125; 接着是“不同包不同类” 12345678910111213141516171819/** * 本例旨在测试不在同一个包的情况下，默认修饰的内部类的访问权限 * * 所以访问权限是，只有依附与外部类，内部类是可以访问的；但无法直接访问 */public class OutPackage_OutClass &#123; public void testInClass()&#123; OutClass out = new OutClass(); // 1.该方法继承或不继承都可以使用 OutClass.InClass in = new OutClass().new InClass(); // 2.外围类对象绑定的方法可以初始化 OutClass.InClass in2 = out.new InClass(); // 该方法与上述原理一样 InClass in3 = out.new InClass(); // 不行 &#125;&#125; 结论从上面的实验可以看出，成员内部类的默认访问修饰符是public，这个public其实是指在依赖于外部类的情况下来看这个内部类其实是public的（其实一开始认为是default，直到发现没有继承时也可通过外围类进行实例化…….） 有疑问的地方其实上述的结论是不敢确定的，因为还看到了这个：Java内部类与访问修饰符所以，真相究竟是什么？ (ㄒoㄒ) 成员内部类的用途其实一旦观察到了这个知识点，总是很容易会想到用途这个实际的东西（…….)，看了看《Think In Java》，里面有这么一个例子：1234567891011121314151617181920212223242526interface Context&#123; public void print();&#125;/** * 内部类的主要用途是在类向上转型（接口）时隐藏实现细节 */public class InnerClassApplication &#123; class InClass implements Context&#123; @Override public void print()&#123; System.out.println("我是实现接口的成员内部类"); &#125; &#125; public Context getContext()&#123; return new InClass(); &#125; @Test public void testInClassApplication()&#123; InnerClassApplication icap = new InnerClassApplication(); icap.getContext().print(); &#125;&#125; 解释一下就是，使用内部类实现一个接口或者继承一个基类，然后向上转型可以隐藏实现的细节 再来看看其它的内部类局部内部类首先来看为什么要这样用，无非是有这样的需求： 实现了某类型的接口，然后隐藏实现返回接口的实例化对象 希望有一个非公共的类来完成某些特殊的任务普通局部内部类定义在一个方法中，作用域就是该方法，相较于成员内部类，就是直接把类放入了方法体中匿名内部类这个就有说头了，匿名就是类没有名字，由JVM自动分配一个特殊助记名123456789101112131415161718public class Test&#123; public Context getContextFromNoNameClass()&#123; return new Context()&#123; @Override public void print()&#123; System.out.println("我是隐式实现了接口的匿名内部类"); &#125; &#125;; &#125; @Test public void testNoNameInClass()&#123; // 可以看到的是尽管没有显式的实现Context接口，但还是重写了print()方法 this.getContextFromNoNameClass().print(); System.out.println(this.getContextFromNoNameClass().getClass()); &#125;&#125; 这个内部类的类名是class InnerClass.InnerClassApplication$1，重点是$1，这个就是JVM给匿名内部类分配的助记符 匿名内部类的一些注意匿名类不可以改变外围类中的属性，所以当在匿名内部类中使用外部类对象时，会要求这个外围类对象加上final修饰符 嵌套类说白了就是给成员内部类加上了static的修饰符，这意味着 要创建嵌套类的对象并不需要依附与外围类（长能耐了） 不能从嵌套类的对象中访问到非静态的外围类对象 同时可以使用InClass in = new OutClass.InClass();这种实例化方法 为什么要有内部类神说要有光，于是便有了光。那为什么会需要内部类呢？ “每个内部类都能独立的继承自一个（接口的）是实现，所以无论外围类是否已经继承了（接口的）实现，对内部类都没有影响” ——《Think in Java》 除此之外，私以为还有上述提到的隐藏实现细节这个原因，所以掌握熟练也是很有必要的，工业界应该少不了这个要求吧？！]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java中==和equals()和hashCode()]]></title>
      <url>%2F2017%2F04%2F30%2FJava%E4%B8%AD%3D%3D%E5%92%8Cequals()%E5%92%8ChashCode()%2F</url>
      <content type="text"><![CDATA[Java中的==我们知道Java中有八大基本数据类型：int、double、char、boolean、float、byte、short、long像String、Integer这种是被包装的非基本数据类型，也被认为是指向引用类型。那么==对于基本数据类型来说，比较的是存储的值，而非基本数据类型比较的则是JVM中存储的地址（堆地址，内存中的存放地址） Java中的equals()Java中所有对象都继承自Object，并拥有其equals()方法，该方法原本采取的比较方式就是==，查看JDK源码123456789 * @param obj the reference object with which to compare. * @return &#123;@code true&#125; if this object is the same as the obj * argument; &#123;@code false&#125; otherwise. * @see #hashCode() * @see java.util.HashMap */public boolean equals(Object obj) &#123; return (this == obj);&#125; 而根据上面讲述的==的比较规则，可以得知equals()针对基本数据类型比较的是值，非基本数据类型比较的是存储的地址。那么我们会有一个疑问了，我们常常使用equals()方法来比较String字符串的值是不是相等，显然与刚才的结论是相悖的，为什么呢？123456789101112131415161718192021222324252627282930 * @param anObject * The object to compare this &#123;@code String&#125; against * * @return &#123;@code true&#125; if the given object represents a &#123;@code String&#125; * equivalent to this string, &#123;@code false&#125; otherwise * * @see #compareTo(String) * @see #equalsIgnoreCase(String) */public boolean equals(Object anObject) &#123; if (this == anObject) &#123; return true; &#125; if (anObject instanceof String) &#123; String anotherString = (String)anObject; int n = value.length; if (n == anotherString.value.length) &#123; char v1[] = value; char v2[] = anotherString.value; int i = 0; while (n-- != 0) &#123; if (v1[i] != v2[i]) return false; i++; &#125; return true; &#125; &#125; return false;&#125; 因此可以看到，String中重写了equals()方法，可以直接比较两个String变量中的值而不是地址，因此如果我们想使用equals()来比较值，需要重写equals()方法 Java中的hashCode()事实上，单纯的重写equals()方法是不够的，为了更好的比较两个对象是否是同一个对象，除了比较其中的值，还需要比较其指向的地址，那么这就需要我们还重写hashCode()方法。 hashCode()方法是比较两个对象的指向的JVM中地址是否相同，HashCode主要用于提供快捷的查找，在HashTable和HashMap中都有使用，HashCode是用来在散列存储结构中确定对象的存储地址的。 更具体的内容可以到另一篇博文中寻找：hashCode()详细说明 注意两个对象的hashCode相同，不代表就是同一个对象/两个对象相同，在hash存储结构中，这只说明了两个对象发生了冲突，被分配在了同一个桶里面。java判断两个对象是否相同还会判断对象引用中存储的地址是否相同（默认） 总结偶然想起了这个“重写equals()就一定要重写hashCode()”这句话，所以顺便就来找一下为什么了。一些细枝末节的东西细细追究起来还是可以回味良久的。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Servlet与JSP-JavaWeb项目食用指南]]></title>
      <url>%2F2017%2F04%2F10%2FServlet%E4%B8%8EJSP-JavaWeb%E9%A1%B9%E7%9B%AE%E9%A3%9F%E7%94%A8%E6%8C%87%E5%8D%97%2F</url>
      <content type="text"><![CDATA[SocraWeb食用指南项目简介本项目是基于Servlet+JSP+DataBase实现的一个商品管理系统，主要目的是学习JavaWeb入门的知识：Servlet、JSP以及EL表达式、Ajax和JSON。完成这个项目主要还是巩固练习JavaWeb的基础知识，为后面的JavaEE框架的学习做铺垫。所以以本人的学习经验来看，这是一个很好的上手Web的练习项目 Github连接项目存储于：https://github.com/SocraHat/SocraWeb.git 环境配置 MySQL数据库：本人的版本是Server version: 5.7.11 MySQL Community Server (GPL) JDK：版本java version “1.8.0_112” Tomcat：apache-tomcat-7.0.73 JDBC-jar包：mysql-connector-java-5.1.40-bin.jar JSTL-jar包：jstl.jar 开发环境：EclipseEE版本 数据库表单创建 首先确认连接MySQL数据库的用户名是root，密码是123456 创建名为web_manage的数据库 再在该数据下创建名为user，manager，goods和goodsInformation的四个数据表 user的SQL语句为：存储注册用户信息 12345CREATE TABLE user( uid varchar(16) PRIMARY KEY, upsd varchar(16) NOT NULL, uname varchar(16) ); manager的SQL语句为：存储管理员信息 12345CREATE TABLE manager( mid varchar(16) PRIMARY KEY, mpsd varchar(10) , mname varchar(16) ); goods的SQL语句为：存储管理商品的信息 123456CREATE TABLE goods( gid int(11) PRIMARY KEY, gname varchar(50), gprice float, gintroduce varchar(50),); goodsInformation的SQL语句为：商品信息的补充 1234CREATE TABLE goodsInformation( gid int(11) PRIMARY KEY, gintroduce varchar(255),); 功能整个项目主要的功能是增删改查 用户的注册登陆以及退出 主页商品的查看和查询商品 用户信息的修改 管理员登陆修改自己的信息 管理员修改商品信息 增加、删除商品信息 过滤器对于没有权限的访问不予通过 操作说明具体的导入工程（Eclipse或者是IDEA）请自行百度，在导入项目后启动Tomcat服务器后就可以直接食用了。但是有几点需要再注意下 用户需要登陆才能查看商品详细信息（权限设置） 只有管理员才有权限去更改商品的各个信息 可能在程序中设置有session的存活时间，所以长时间不对页面操作而导致登陆状态消失时请重新登录 修改商品信息、用户信息、管理员信息时一定注意不能是空值null，另外在新增商品时注意商品的编号不能是0 其余的基本操作可以自己去尝试，和一般的网页处理事务的顺序原理相似 项目总结项目前后历时还是有个个把月的，但主要还是最后的这两天完成实现了大部分功能，虽然只是一个初级的小项目，但是内心还是充满了欢喜的。这部分知识不敢说全部掌握，起码也有个六七八了，后面的细节，再做补充。 难点感觉项目中比较棘手的地方： 页面的合理设计：追求一定美观合适，也使用了BootStrap 前后台数据的交互：有时需要用到Servlet到JSP或是Servlet的转发，有时需要用到Session，有时需要用到JS的跳转，错综复杂，但是编码问题，调用的方法，需要后续再补充一篇细节总结 使用JS来获取页面的表格中的数据并使用Ajax传递到后台 登陆后的登出以及验证问题 程序和数据库交互问题：如何正确又高效的查询 初步尝试MVC（Servlet+JSP+JavaBean）模式，虽然分了层，但是感觉还是不够清晰简洁 使用过滤器实现权限的判断和页面的跳转 责任声明本项目纯属个人项目，因为本人能力问题，可能某些地方的处理不合适或是有误，欢迎大家提出宝贵意见。若是对您学习造成了误导，本人表示十分抱歉。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[深入理解ArrayList]]></title>
      <url>%2F2017%2F03%2F30%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3ArrayList%2F</url>
      <content type="text"><![CDATA[是的，这又是一篇转文讲道理，有时候转载博文也是挺效率得一件事，毕竟没有那么多的时间去自己抠（哎），毕竟我是站在dalao得肩膀上啊ArrayList的实现原理侵删 本篇是研究一下ArrayList的底层实现，顺便把List的底也给掀了 ArrayList概述ArrayList是List接口的可变数组的实现。实现了所有可选列表的操作，并允许包括null在内的所有元素。同时ArrayList也有内部的方法用于操作数组大小以及元素。每个ArrayList实例都有一个容量，该容量是指用来存储列表元素的数组的大小。它总是至少等于列表的大小。随着向ArrayList中不断添加元素，其容量也自动增长。自动增长会带来数据向新数组的重新拷贝，因此，如果可预知数据量的多少，可在构造ArrayList时指定其容量。在添加大量元素前，应用程序也可以使用ensureCapacity操作来增加ArrayList实例的容量，这可以减少递增式再分配的数量。另外需要提及的一点就是，ArrayList并不是线程安全的，多线程使用时需要注意注意同步。 来看一下源码其实本质就是对数组的操作，我们在使用时的简单操作的原理是透明的。 存储实现1234567/** * The array buffer into which the elements of the ArrayList are stored. * The capacity of the ArrayList is the length of this array buffer. Any * empty ArrayList with elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA * will be expanded to DEFAULT_CAPACITY when the first element is added. */ transient Object[] elementData; // non-private to simplify nested class access 构造方法ArrayList提供了三种方式的构造器，可以构造一个默认初始容量为10的空列表，构造一个指定初始容量的数组，以及构造一个包含指定Collection元素的列表，这些元素按照collection的迭代器返回它们的顺序。123456789101112131415161718public ArrayList() &#123; this(10); &#125; public ArrayList(int initialCapacity) &#123; super(); if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); this.elementData = new Object[initialCapacity]; &#125; public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); size = elementData.length; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; 存储常见的添加、替换方法12345678// 用指定的元素替代此列表中指定位置上的元素，并返回以前位于该位置上的元素。 public E set(int index, E element) &#123; RangeCheck(index); // 有一个强制转型的操作 E oldValue = (E) elementData[index]; elementData[index] = element; return oldValue; &#125; 123456// 将指定的元素添加到此列表的尾部。 public boolean add(E e) &#123; ensureCapacity(size + 1); elementData[size++] = e; return true; &#125; 1234567891011121314// 将指定的元素插入此列表中的指定位置。 // 如果当前位置有元素，则向右移动当前位于该位置的元素以及所有后续元素（将其索引加1）。 public void add(int index, E element) &#123; if (index &gt; size || index &lt; 0) throw new IndexOutOfBoundsException("Index: "+index+", Size: "+size); // 如果数组长度不足，将进行扩容。 ensureCapacity(size+1); // Increments modCount!! // 将 elementData中从Index位置开始、长度为size-index的元素， // 拷贝到从下标为index+1位置开始的新的elementData数组中。 // 即将当前位于该位置的元素以及所有后续元素右移一个位置。 System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++; &#125; 123456789// 按照指定collection的迭代器所返回的元素顺序，将该collection中的所有元素添加到此列表的尾部。 public boolean addAll(Collection&lt;? extends E&gt; c) &#123; Object[] a = c.toArray(); int numNew = a.length; ensureCapacity(size + numNew); // Increments modCount System.arraycopy(a, 0, elementData, size, numNew); size += numNew; return numNew != 0; &#125; 123456789101112131415161718// 从指定的位置开始，将指定collection中的所有元素插入到此列表中。 public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; if (index &gt; size || index &lt; 0) throw new IndexOutOfBoundsException( "Index: " + index + ", Size: " + size); Object[] a = c.toArray(); int numNew = a.length; ensureCapacity(size + numNew); // Increments modCount int numMoved = size - index; if (numMoved &gt; 0) System.arraycopy(elementData, index, elementData, index + numNew, numMoved); System.arraycopy(a, 0, elementData, index, numNew); size += numNew; return numNew != 0; &#125; 某些细节看到这里我注意到有两个方法出现的次数很高：ensureCapacity()和System.arraycopy() 读取123456// 返回此列表中指定位置上的元素。 public E get(int index) &#123; RangeCheck(index); return (E) elementData[index]; &#125; 删除指定下标删除或者指定元素删除1234567891011121314// 移除此列表中指定位置上的元素。 public E remove(int index) &#123; RangeCheck(index); modCount++; E oldValue = (E) elementData[index]; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // Let gc do its work return oldValue; &#125; 12345678910111213141516171819// 移除此列表中首次出现的指定元素（如果存在）。这是应为ArrayList中允许存放重复的元素。 public boolean remove(Object o) &#123; // 由于ArrayList中允许存放null，因此下面通过两种情况来分别处理。 if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; // 类似remove(int index)，移除列表中指定位置上的元素。 fastRemove(index); return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false; &#125; 注意元素被移除后，该元素后面的元素的下标值都减一了，使用时需要注意 调整数组容量每次对ArrayList进行操作之前都会判断一下容量的大小，如果容量不够，会及时的自动扩充。但是通过我们手动调用，给ensuerCapacity输入参数，可以避免方法重复递归调用123456789101112public void ensureCapacity(int minCapacity) &#123; modCount++; int oldCapacity = elementData.length; if (minCapacity &gt; oldCapacity) &#123; Object oldData[] = elementData; int newCapacity = (oldCapacity * 3)/2 + 1; if (newCapacity &lt; minCapacity) newCapacity = minCapacity; // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); &#125; &#125; 可以明显的看出，数组的每次自我扩容是原来的1.5倍，较为保守。ArrayList还给我们提供了将底层数组的容量调整为当前列表保存的实际元素的大小的功能。它可以通过trimToSize方法来实现。1234567public void trimToSize() &#123; modCount++; int oldCapacity = elementData.length; if (size &lt; oldCapacity) &#123; elementData = Arrays.copyOf(elementData, size); &#125; &#125; Fail-Fast机制（快速失败机制）ArrayList也采用了快速失败的机制，通过记录modCount参数来实现。在面对并发的修改时，迭代器很快就会完全失败，而不是冒着在将来某个不确定时间发生任意不确定行为的风险。 “快速失败”也就是fail-fast，它是Java集合的一种错误检测机制。当多个线程对集合进行结构上的改变的操作时，有可能会产生fail-fast机制。记住是有可能，而不是一定。例如：假设存在两个线程（线程1、线程2），线程1通过Iterator在遍历集合A中的元素，在某个时候线程2修改了集合A的结构（是结构上面的修改，而不是简单的修改集合元素的内容），那么这个时候程序就会抛出 ConcurrentModificationException 异常，从而产生fail-fast机制。 ArrayList值得看一看的基本就在这里，其余的方法使用时可自行查阅API文档。（所以说，这就是一个自动的可以存放任意类型对象的数组，使用时很方便） 那就不得不说一下Vector打开Vector源码一看，果不出期然，Vector的实现与ArrayList的底层实现基本如出一辙，除了线程安全基本没有改变什么（重量级操作）其实查看源码时，很容易注意到，很多方法都用synchronized修饰了，这也就是线程安全的实现原理。 顺便看一看LinkedList虽然实现了List的接口，但底层并不是对数组进行的操作，而是使用双向循环链表实现。继承于AbstractSequentialList，可以被当作堆栈、队列或双端队列进行操作。FROM-Java集合—LinkedList源码解析侵删 链表节点Entry其中的链表节点元素都是Entry类型的实例（包含三个变量：previous、next、element）1234567891011private static class Entry&lt;E&gt; &#123; E element; // 业务数据 Entry&lt;E&gt; next; // 后节点信息 Entry&lt;E&gt; previous; // 前节点信息 Entry(E element, Entry&lt;E&gt; next, Entry&lt;E&gt; previous) &#123; this.element = element; this.next = next; this.previous = previous; &#125;&#125; 构造方法因为是双向-循环-链表第一种构造方法在初始化时只有头元素的情况下，previous和next都指向自己，形成一个闭环，这是称为循环的原因。第二种方法是接收一个Collection参数c，调用第一种方法构造一个空链表（首节点不算），然后通过addAll()方法将c中的元素全部添加到链表中。 插入这里是重头戏，dalao已经讲解的很好了，丝毫不敢稍有改动。 初始化后LinkedList是首结点闭环 再初始化一个预添加的Entry实例，Entry newEntry = newEntry(e, entry, entry.previous); 调整新加入节点和首节点的前后指针12newEntry.previous.next = newEntry;newEntry.next.previous = newEntry; 再有新的节点插入时，过程是这样的 新建一个节点 修改前后指针 清除12345678910111213141516171819public void clear() &#123; Entry&lt;E&gt; e = header.next; // e可以理解为一个移动的“指针”，因为是循环链表，所以回到header的时候说明已经没有节点了 while (e != header) &#123; // 保留e的下一个节点的引用 Entry&lt;E&gt; next = e.next; // 解除节点e对前后节点的引用 e.next = e.previous = null; // 将节点e的内容置空 e.element = null; // 将e移动到下一个节点 e = next; &#125; // 将header构造成一个循环链表，同构造方法构造一个空的LinkedList header.next = header.previous = header; // 修改size size = 0; modCount++;&#125; 删除12345678910111213141516171819private E remove(Entry&lt;E&gt; e) &#123; if (e == header) throw new NoSuchElementException(); // 保留将被移除的节点e的内容 E result = e.element; // 将前一节点的next引用赋值为e的下一节点 e.previous.next = e.next; // 将e的下一节点的previous赋值为e的上一节点 e.next.previous = e.previous; // 上面两条语句的执行已经导致了无法在链表中访问到e节点，而下面解除了e节点对前后节点的引用 e.next = e.previous = null; // 将被移除的节点的内容设为null e.element = null; // 修改size大小 size--; modCount++; // 返回移除节点e的内容 return result;&#125; 简单说就是，先把前后节点互相连接起来，再清空该节点的所有数据。然后等待GC回收即可 get()方法感觉这是一个需要关注一点的地方123456789101112131415161718// 获取双向链表中指定位置的节点 private Entry&lt;E&gt; entry(int index) &#123; if (index &lt; 0 || index &gt;= size) throw new IndexOutOfBoundsException("Index: "+index+ ", Size: "+size); Entry&lt;E&gt; e = header; // 获取index处的节点。 // 若index &lt; 双向链表长度的1/2,则从前先后查找; // 否则，从后向前查找。 if (index &lt; (size &gt;&gt; 1)) &#123; for (int i = 0; i &lt;= index; i++) e = e.next; &#125; else &#123; for (int i = size; i &gt; index; i--) e = e.previous; &#125; return e; &#125; 一个小细节就可以提高性能 总结其实就一个数组/链表，基本原理就是这样子，无非是Java给你封装好了直接拿来用就好了┑(￣Д ￣)┍把这个List更完，常用的集合框架就只剩一个TreeMap 了，由于底层是使用红黑树实现的（虽然看了好几遍插删，但是记不住啊），日后补完JVM垃圾回收在去干它好了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java集合框架的并发安全研究]]></title>
      <url>%2F2017%2F03%2F29%2FJava%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6%E7%9A%84%E5%B9%B6%E5%8F%91%E5%AE%89%E5%85%A8%E7%A0%94%E7%A9%B6%2F</url>
      <content type="text"><![CDATA[早就想开这个坑了讲真，从开始慢慢深入Java后，发现了并发这个最关键的点之一，不了解这个怕是不敢说熟悉Java啊，呐，择日不如撞日，就今天来打第一炮好了 我站在dalao的肩膀上其实这是一篇转文，来自dalao博文侵删在集合框架中，有些类是线程安全的，这些都是jdk1.1中的出现的。在jdk1.2之后，就出现许许多多非线程安全的类。 线程安全的类/接口 Vector：底层是容量默认为10的Object数组（翻看ArrayList源码，底层也是Object数组），比ArrayList多了个同步化机制（线程安全），但是效率较低，现不建议使用 Statck：继承自Vector，所以其也是线程安全的 HashTable：相较于HashMap多了同步机制，但是同样，带来了效率的底下，具体区别看HashMap和HashTable的区别 Enumeration：枚举类，相当于迭代器（这个真没什么了解） 注意除了上述列出的类，其余的集合框架中的类或者是接口都是非线程安全的（这不等于线程不安全）。因为保证了同步，所以相较而言就比较笨重，效率较低。 呐，顺便再提一下StringBuffer和StringBuilder好了，二者区别就是StringBuffer是线程安全的String、StringBuffer与StringBuilder之间区别 事实事实就是今天一晚上都在研究集合框架研究嗨了，从HashSet到把Set翻了个底朝天，从又看HashMap到现在看集合框架的并发安全性，首先需要明确的是这就是个坑，暂时放在这里，后面再开始啃Java并发之后再详谈，今天还要再看一看Java锁呢，垃圾回收机制怕是只能到明天再继续了]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[深入理解HashSet]]></title>
      <url>%2F2017%2F03%2F29%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3HashSet%2F</url>
      <content type="text"><![CDATA[首先是有一个悲伤的故事讲道理，这是面试时遇到的第一个卡壳以至于转移面试官注意力的地方（……），还好之前有被人指点一下加确实已经仔细研究过HashMap，才不至于无法补救 其次我TM惊呆了本想着回来以后好好看看HashSet的底层实现，结果打开源码一看的我惊呆了wocao怎么这么刺眼呢？你是set啊，你是Collection的子类啊，你叔叔才是Map啊，你这样我心好痛啊冷静下来我仔细一想，Set不能有重复的元素，HashMap不允许有重复的键，又是一口老血，当时也没想到也没敢去这么想 转一下dalao的博客于是接着去看网上的dalao的博客，发现了这一篇私自转载dalao博文侵删 HashSet概述和实现HashSet实现Set接口，由哈希表（实际上是一个HashMap实例）支持。它不保证set 的迭代顺序；特别是它不保证该顺序恒久不变，此类允许使用null元素。在HashSet中，元素都存到HashMap键值对的Key上面，而Value时有一个统一的值private static final Object PRESENT = new Object();， HashSet插入当有新值加入时，底层的HashMap会判断Key值是否存在（HashMap细节请移步深入理解HashMap），如果不存在，则插入新值，同时这个插入的细节会依照HashMap插入细节；如果存在就不插入 删除同HashMap删除原理 源码分析盗（xue）用（xi）一下dalao 的分析代码，侵权请告之，立马删除123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169public class HashSet&lt;E&gt; extends AbstractSet&lt;E&gt; implements Set&lt;E&gt;, Cloneable, java.io.Serializable &#123; static final long serialVersionUID = -5024744406713321676L; // 底层使用HashMap来保存HashSet中所有元素。 private transient HashMap&lt;E,Object&gt; map; // 定义一个虚拟的Object对象作为HashMap的value，将此对象定义为static final。 private static final Object PRESENT = new Object(); /** * 默认的无参构造器，构造一个空的HashSet。 * * 实际底层会初始化一个空的HashMap，并使用默认初始容量为16和加载因子0.75。 */ public HashSet() &#123; map = new HashMap&lt;E,Object&gt;(); &#125; /** * 构造一个包含指定collection中的元素的新set。 * * 实际底层使用默认的加载因子0.75和足以包含指定 * collection中所有元素的初始容量来创建一个HashMap。 * @param c 其中的元素将存放在此set中的collection。 */ public HashSet(Collection&lt;? extends E&gt; c) &#123; map = new HashMap&lt;E,Object&gt;(Math.max((int) (c.size()/.75f) + 1, 16)); addAll(c); &#125; /** * 以指定的initialCapacity和loadFactor构造一个空的HashSet。 * * 实际底层以相应的参数构造一个空的HashMap。 * @param initialCapacity 初始容量。 * @param loadFactor 加载因子。 */ public HashSet(int initialCapacity, float loadFactor) &#123; map = new HashMap&lt;E,Object&gt;(initialCapacity, loadFactor); &#125; /** * 以指定的initialCapacity构造一个空的HashSet。 * * 实际底层以相应的参数及加载因子loadFactor为0.75构造一个空的HashMap。 * @param initialCapacity 初始容量。 */ public HashSet(int initialCapacity) &#123; map = new HashMap&lt;E,Object&gt;(initialCapacity); &#125; /** * 以指定的initialCapacity和loadFactor构造一个新的空链接哈希集合。 * 此构造函数为包访问权限，不对外公开，实际只是是对LinkedHashSet的支持。 * * 实际底层会以指定的参数构造一个空LinkedHashMap实例来实现。 * @param initialCapacity 初始容量。 * @param loadFactor 加载因子。 * @param dummy 标记。 */ HashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;E,Object&gt;(initialCapacity, loadFactor); &#125; /** * 返回对此set中元素进行迭代的迭代器。返回元素的顺序并不是特定的。 * * 底层实际调用底层HashMap的keySet来返回所有的key。 * 可见HashSet中的元素，只是存放在了底层HashMap的key上， * value使用一个static final的Object对象标识。 * @return 对此set中元素进行迭代的Iterator。 */ public Iterator&lt;E&gt; iterator() &#123; return map.keySet().iterator(); &#125; /** * 返回此set中的元素的数量（set的容量）。 * * 底层实际调用HashMap的size()方法返回Entry的数量，就得到该Set中元素的个数。 * @return 此set中的元素的数量（set的容量）。 */ public int size() &#123; return map.size(); &#125; /** * 如果此set不包含任何元素，则返回true。 * * 底层实际调用HashMap的isEmpty()判断该HashSet是否为空。 * @return 如果此set不包含任何元素，则返回true。 */ public boolean isEmpty() &#123; return map.isEmpty(); &#125; /** * 如果此set包含指定元素，则返回true。 * 更确切地讲，当且仅当此set包含一个满足(o==null ? e==null : o.equals(e)) * 的e元素时，返回true。 * * 底层实际调用HashMap的containsKey判断是否包含指定key。 * @param o 在此set中的存在已得到测试的元素。 * @return 如果此set包含指定元素，则返回true。 */ public boolean contains(Object o) &#123; return map.containsKey(o); &#125; /** * 如果此set中尚未包含指定元素，则添加指定元素。 * 更确切地讲，如果此 set 没有包含满足(e==null ? e2==null : e.equals(e2)) * 的元素e2，则向此set 添加指定的元素e。 * 如果此set已包含该元素，则该调用不更改set并返回false。 * * 底层实际将将该元素作为key放入HashMap。 * 由于HashMap的put()方法添加key-value对时，当新放入HashMap的Entry中key * 与集合中原有Entry的key相同（hashCode()返回值相等，通过equals比较也返回true）， * 新添加的Entry的value会将覆盖原来Entry的value，但key不会有任何改变， * 因此如果向HashSet中添加一个已经存在的元素时，新添加的集合元素将不会被放入HashMap中， * 原来的元素也不会有任何改变，这也就满足了Set中元素不重复的特性。 * @param e 将添加到此set中的元素。 * @return 如果此set尚未包含指定元素，则返回true。 */ public boolean add(E e) &#123; return map.put(e, PRESENT)==null; &#125; /** * 如果指定元素存在于此set中，则将其移除。 * 更确切地讲，如果此set包含一个满足(o==null ? e==null : o.equals(e))的元素e， * 则将其移除。如果此set已包含该元素，则返回true * （或者：如果此set因调用而发生更改，则返回true）。（一旦调用返回，则此set不再包含该元素）。 * * 底层实际调用HashMap的remove方法删除指定Entry。 * @param o 如果存在于此set中则需要将其移除的对象。 * @return 如果set包含指定元素，则返回true。 */ public boolean remove(Object o) &#123; return map.remove(o)==PRESENT; &#125; /** * 从此set中移除所有元素。此调用返回后，该set将为空。 * * 底层实际调用HashMap的clear方法清空Entry中所有元素。 */ public void clear() &#123; map.clear(); &#125; /** * 返回此HashSet实例的浅表副本：并没有复制这些元素本身。 * * 底层实际调用HashMap的clone()方法，获取HashMap的浅表副本，并设置到HashSet中。 */ public Object clone() &#123; try &#123; HashSet&lt;E&gt; newSet = (HashSet&lt;E&gt;) super.clone(); newSet.map = (HashMap&lt;E, Object&gt;) map.clone(); return newSet; &#125; catch (CloneNotSupportedException e) &#123; throw new InternalError(); &#125; &#125; &#125; 注意 说白了，HashSet就是限制了功能的HashMap，所以了解HashMap的实现原理，这个HashSet自然就通 对于HashSet中保存的对象，主要要正确重写equals方法和hashCode方法，以保证放入Set对象的唯一性 虽说时Set是对于重复的元素不放入，倒不如直接说是底层的Map直接把原值替代了（这个Set的put方法的返回值真有意思） HashSet没有提供get()方法，愿意是同HashMap一样，Set内部是无序的，只能通过迭代的方式获得 说起来你可能不信本来是打算分开写集合框架的底层分析的，直到我发现，LinkedHashSet是继承自HashSet，底层实现是LinkedHashMap。并且其初始化时直接super(......)，瞬间我就觉得，Set写在一起得了 LinkedHashSet同HashSet相比并没有实现新的功能（新的方法），只不过把HashSet中预留的构造方法启用了，因而可以实现有序插入，而这个具体的实现要去看LinkedHashMap了，我们使用时是不需要再可以去设置参数的，直接拿来用即可。1234567/** * The iteration ordering method for this linked hash map: &lt;tt&gt;true&lt;/tt&gt; * for access-order, &lt;tt&gt;false&lt;/tt&gt; for insertion-order. * * @serial */final boolean accessOrder; 查看了LinkedHashMap的构造方法后，发现其因为继承自HashMap，所以其底层实现也是HashMap!!!（呵呵，我已经发现了……怪不得还是得主要研究HashMap啊），然后发现了LinkedHashMap调用父类构造方法初始化时，还顺便设置了变量accessOrder = false，看上面得源码可以知道，这是给了迭代器一个参数，false代表迭代时使用插入得顺序（追根溯源了，真爽） 偶然发现查看源码时，我发现了一个奇怪的重写的方法：public Spliterator&lt;E&gt; spliterator()，查了查资料发现叫做可分割迭代器，这个接口是为了并行遍历数据源中的元素而设计的迭代器，为了更好的发挥多核CPU的能力。其实这样我想起了要去关注一下集合框架中的并发安全了。 TreeSet根据Set的这个尿性，我先猜测一波，TreeSet的底层实现是TreeMap（而且我在猜TreeMap的底层实现借助了HashMap）。一看源码，哎呦我去，还真是（呵呵，到底谁才是你爹…..心疼一波Collection,Map又不继承Collection接口）123public TreeSet() &#123; this(new TreeMap&lt;E,Object&gt;());&#125; TreeSet特点与实现机制TreeSet中存放的元素是有序的（不是插入时的顺序，是有按关键字大小排序的），且元素不能重复。而如何实现有序存储，就需要有一个比较器，其实说起来，TreeSet更受关注的是不重复且有序，这个有序就需要有一个compare的过程，因此会需要参数实现Comparable接口。12345678910111213141516/** * Constructs a new, empty tree set, sorted according to the specified * comparator. All elements inserted into the set must be &lt;i&gt;mutually * comparable&lt;/i&gt; by the specified comparator: &#123;@code comparator.compare(e1, * e2)&#125; must not throw a &#123;@code ClassCastException&#125; for any elements * &#123;@code e1&#125; and &#123;@code e2&#125; in the set. If the user attempts to add * an element to the set that violates this constraint, the * &#123;@code add&#125; call will throw a &#123;@code ClassCastException&#125;. * * @param comparator the comparator that will be used to order this set. * If &#123;@code null&#125;, the &#123;@linkplain Comparable natural * ordering&#125; of the elements will be used. */public TreeSet(Comparator&lt;? super E&gt; comparator) &#123; this(new TreeMap&lt;&gt;(comparator));&#125; 所以说所以说使用Set需要注意的还是根据自己的需求选取正确的存储结构即可，而因为并没有get()方法给你使用，所以还是要用迭代器来获取想要的元素，然后本次Set深入分析到此结束，我要去再开一坑研究TreeMap了（滑稽） 小总结经历这么一次滑稽的经历，看来真的有必要把几个常用的集合框架的底层实现都看一遍，以免再次搞出这样的尴尬（手动滑稽）其实深入到这个程度我觉得常用的集合除了List的家族还有Queue，其实都可以规约为深入理解HashMap，来，就是这个节奏。走起。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM中String常量池与运行时常量池]]></title>
      <url>%2F2017%2F03%2F29%2FJVM%E4%B8%ADString%E5%B8%B8%E9%87%8F%E6%B1%A0%E4%B8%8E%E8%BF%90%E8%A1%8C%E6%97%B6%E5%B8%B8%E9%87%8F%E6%B1%A0%2F</url>
      <content type="text"><![CDATA[Start with JVM周志明先生著-《深入理解Java虚拟机》，书买回来好几天了，但是最近才准备开始搞一搞了（哭瞎…..）。首先是第一章的Java以及JVM发展历史，大概知道了现行的应用最广泛的Java虚拟机是HotSpot，当然一些商业公司也有使用自己的虚拟机。 JVM运行时数据区这是放在Java内存区域与内存溢出异常里面的必备知识，描述了Java虚拟机在运行时的数据区域↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓私有 程序计数器：记录当前线程所执行字节码的行号指示器 虚拟机栈：存放了当前线程调用方法的局部变量表、操作数栈、动态链接、方法返回值等信息（可以理解为线程的栈） 本地方法栈：为虚拟机使用的Native方法提供服务，后多与JVM Stack合并为一起 共享 Java堆：占据了虚拟机管理内存中最大的一块（没想到吧），唯一目的就是存放对象实例（与引用是两个概念），也是垃圾回收器主要管理的地方，故又称GC堆。先开坑，后面讲垃圾回收机制再详述 方法区：存储加载的类信息、常量区、静态变量、JIT（即时编译器）处理后的数据等，类的信息包含类的版本、字段、方法、接口等信息。需要注意是常量池就在方法区中，也是我们这次需要关注的地方。 提一下这个Native方法指得就是Java程序调用了非Java代码，算是一种引入其它语言程序的接口 看一下方法区方法区因为总是存放不会轻易改变的内容，故又被称之为“永久代”。HotSpot也选择把GC分代收集扩展至方法区，但也容易遇到内存溢出问题。可以选择不实现垃圾回收，但如果回收就主要涉及常量池的回收和类的卸载（这里开坑，后续补上链接） 运行时常量池回归本次讨论正题，主要是在看Java和C++的一些原理时，老是有“常量池”这个我一知半解的讨厌的字词，烦的一批，今天我就来探一探究竟。 JVM中运行时常量池在方法区中，因为是建立在JDK1.7/1.8的基础上来研究这个，所以我先认为String常量池在堆中。Class文件中除了类的版本、字段、方法、接口等描述信息，还有常量池，用于存放编译期生成的各种字面量和符号引用 运行时常量池与Class文件常量池区别 JVM对Class文件中每一部分的格式都有严格的要求，每一个字节用于存储那种数据都必须符合规范上的要求才会被虚拟机认可、装载和执行；但运行时常量池没有这些限制，除了保存Class文件中描述的符号引用，还会把翻译出来的直接引用也存储在运行时常量区 相较于Class文件常量池，运行时常量池更具动态性，在运行期间也可以将新的变量放入常量池中，而不是一定要在编译时确定的常量才能放入。最主要的运用便是String类的intern()方法 在方法区中，常量池有运行时常量池和Class文件常量池；但其中的内容是否完全不同，暂时还未得知 String.intern()检查字符串常量池中是否存在String并返回池里的字符串引用；若池中不存在，则将其加入池中，并返回其引用。这样做主要是为了避免在堆中不断地创建新的字符串对象 那class常量池呢？具体的等分析到Class文件格式再来填这个坑，先来看常量池中的内容：看一下dalao的博客Class文件中常量池详解 看一看String常量池（的特殊姿势）吧在研究这个的时候我也上网看了别人的博客，有的人做出了实验，我也试一下 实验一123456public class Test&#123; public static String a = "a"; public static void main()&#123; String b = "b"; &#125;&#125; 使用Java自带的反编译工具反编译一下，编译后输入javap -verbose Test.class 可以发现两个静态String变量都放入了常量池中 实验二12345public class Test2&#123; public static String str = "laji" + "MySQL"; public static void main()&#123; &#125;&#125; 在编译前先分析一波，按理说，既然是静态String常量，那么理应出现在常量池（Constant Pool）中，但 来看看进阶版的Test2_212345678public class Test2_2&#123; public static void main(String[] args)&#123; String string1 = "laji"; String string2 = "MySQL"; String string3 = string1+string2; String string4 = string1+"C"; &#125;&#125; 这个的结果就更有意思了↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓总商量个实验，可以看出 对于直接做+运算的两个字符串（字面量）常量，并不会放入String常量池中，而是直接把运算后的结果放入常量池中 对于先声明的字符串字面量常量，会放入常量池，但是若使用字面量的引用进行运算就不会把运算后的结果放入常量池中了 总结一下就是JVM会对String常量的运算进行优化，未声明的，只放结果；已经声明的，只放声明 实验三123456789public class Test3&#123; public static void main(String[] args)&#123; String str = "laji"; String str2 = new String("MySQL"); String str3 = new String("laji"); System.out.println(str==str3);// 运行后结果为false &#125;&#125; 结果为：这个实验三包含了很多内容，首先是new一个对象时，明明是在堆中实例化一个对象，怎么会出现常量池中？ 这里的&quot;MySQL&quot;并不是字符串常量出现在常量池中的，而是以字面量出现的，实例化操作（new的过程）是在运行时才执行的，编译时并没有在堆中生成相应的对象 最后输出的结果之所以是false，就是因为str指向的”laji”是存放在常量池中的，而str3指向的”laji”是存放在堆中的，==比较的是引用（地址），当然是false 实验四主要是为了解释一下intern()方法的用处1234567891011public class Test4&#123; public static void main(String[] args)&#123; String str = "laji"; String str2 = new String("laji"); String str3 = null; System.out.println(str==str2);// 运行后结果为false str3 = str2.intern(); System.out.println(str==str3);// 运行后结果为true &#125;&#125; 显然，str3在初始化的时候是从字符串常量池中获取到的值 String常量池随JDK的改变JDK1.7中JVM把String常量区从方法区中移除了；JDK1.8中JVM把String常量池移入了堆中，同时取消了“永久代”，改用元空间代替（Metaspace）12345678910111213141516171819202122import java.util.ArrayList;public class TestString &#123; public static void main(String[] args) &#123; String str = "abc"; char[] array = &#123;'a', 'b', 'c'&#125;; String str2 = new String(array); //使用intern()将str2字符串内容放入常量池 str2 = str2.intern(); //这个比较用来说明字符串字面常量和我们使用intern处理后的字符串是在同一个地方 System.out.println(str == str2); //那好，下面我们就拼命的intern吧 ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(); for (int i = 0; i &lt; 10000000; i++) &#123; String temp = String.valueOf(i).intern(); list.add(temp); &#125; &#125;&#125; 这个实验最早是2014年有人实验过的，ta得出的结论是Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: PermGen space，然而时至今日，我自己按照ta的代码跑了一遍，并没有出现上述的错误，虽然一段时间内内存资源占用呈上升状态。猜想：所使用JDK版本不同，对于String常量池存放的位置已经发生了改变；或者是两者的电脑硬件不同实验出处 然后，我又看到了这个新的实验证明String常量池的位置，JVM参数设置：-Xmx5m -XX:MaxPermSize=5m1234567891011121314import java.util.ArrayList;import java.util.List;public class TestString2 &#123; public static void main(String[] args) &#123; // TODO Auto-generated method stub List&lt;String&gt; list = new ArrayList&lt;String&gt;(); int i = 0; while(true)&#123; list.add(String.valueOf(i++).intern()); &#125; &#125;&#125; 因为JDK版本不同的原因，我无法按照上述的代码得出原博文相同的结果，这是我自己运行出的结果 sun官方说明：并行/并发回收器在GC回收时间过长时会抛出OutOfMemroyError。过长的定义是，超过98%的时间用来做GC并且回收了不到2%的堆内存。用来避免内存过小造成应用不能正常工作。 对照着结果以及上面的博客可以得知，这显然是在堆中的垃圾回收发生了异常所致。在内存满后，会进行垃圾回收，但又会intern新的字符串到String常量池中，那么就会导致垃圾回收器一直不停的干着没有意义的活，时间一久，自然报错。同时原文中所提及的这一句话我觉得需要注意一下： 另外一点值得注意的是，虽然String.intern()的返回值永远等于字符串常量。但这并不代表在系统的每时每刻，相同的字符串的intern()返回都会是一样的（虽然在95%以上的情况下，都是相同的）。因为存在这么一种可能：在一次intern()调用之后，该字符串在某一个时刻被回收，之后，再进行一次intern()调用，那么字面量相同的字符串重新被加入常量池，但是引用位置已经不同。 综上，虽自己没有太多的明确结果证明，但是我想这已经能够印证JDK版本变化导致的String常量池位置的改变。 日常summary这个本来是今天计划打算进行的一部分，结果好像进入牛角尖了，一定要深入一下…..，结果垃圾回收也没有看多少，明天继续。但终于算是把这一块搞的一清二楚了，😜 吐槽一下第一次听说垃圾分代时是懵逼的，分袋？还用分袋装垃圾？这是真的吗？现在了解了才发现自己的想法真是666]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java中的volatile关键字]]></title>
      <url>%2F2017%2F03%2F18%2FJava%E4%B8%AD%E7%9A%84volatile%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
      <content type="text"><![CDATA[Java并发中的可见性与原子性Java并发是一个十分重要的知识点，然而我并不会（…..），慢慢上手吧，今天来看一看这个volatile 可见性可见性是指线程之间的可见性，也就是一个线程修改的结果对另一个线程是可见的。使用volatile修饰的变量就会具有可见性。但需要注意的是volatile只能保证被修饰的内容具有可见性，而不能保证具有原子性，因而就会存在线程安全问题 原子性原子是不可分割的，因此原子操作也是指某些操作是连续的不可分割的（操作系统中有详细的解释）。非原子操作会存在线程安全问题，而加上synchronized关键字后就会使操作变成原子操作1234// ......int a = 0;a = a + 1;// ...... 这么一个简单的过程，CPU在运行的时候会先读取a的值，然后相加计算的结果会再赋值给a；这时候如果是多个线程在工作，那么在赋值操作前CPU读取的值到底是0还是1呢？（多个线程同时工作，无法得知哪个线程在CPU执行的先后顺序，此时使用的a值说不定就是彼时计算后的a值） 重排序-Java多线程再看下面的内容之前，先要看一看这个重排序：指令重排序，是指编译器或程序运行时环境为了优化程序性能而采取的对指令重新排序执行的一种手段简单的说，两条语句在执行时，处于优化的原因，谁先执行谁后不一定 synchronized和volatile为了解决线程并发的问题，Java引入了同步快synchronized和volatile关键字机制 synchronized关键字：被synchronized修饰的块结构在多线程访问时，同一时刻只能有一个线程能有访问的到块内容 volatile关键字：volatile修饰的变量，线程在每次访问的时候，都会读取变量最后一次修改的值 注意 synchronized保证了原子性，但仍不代表线程安全 如果一定要保证线程安全，可以使用重入锁ReentrantLock volatile原理再来仔细探讨一下volatile深入的原理，这是一种相对较弱的同步机制，能够确保使变量的更新对其他线程是可见的。被volatile声明的变量，编译器与运行时的环境都会注意到这是一个共享的变量，因此不会将该变量上的操作与其他内容操作一起重排序。这是因为volatile变量不会被缓存在寄存器或者其它对处理器不可见的地方，因此每次访问volatile变量都会返回最新更新的值。 处理器在访问volatile变量时不会执行加锁操作，因此也就不会使执行线程阻塞，因此volatile变量是一种比synchronized关键字更为轻量级（稍弱）的同步机制 先看一下普通状态下的线程工作的内存变化↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓JVM在运行时会对不同的线程分配自己的线程栈（线程内存），线程栈保存了线程运行时变量的信息。当线程想访问一个对象的值的时候，会进行如下的操作： 首先，通过对象的引用找到对应在堆内存中变量的值 然后把该值load到本地线程内存中，建立一个变量的副本，之后线程就不在和对内存中变量的值有任何关系，而是直接修改副本中的值 在修改完副本变量值后，在线程完全退出前，会自动把线程副本变量的值写回到对象在堆中的值，这样堆中变量的值就发生了变化 如上图所示，取副本中的值（use）和写到副本中（asign）可以多次出现。重要的是，上图中的操作并不是原子性的，就是说当线程read和load后，如果主内存中变量的值发生了改变，线程无从得知，进而导致最后计算出的结果并不是我们预想中的。 回过头来看一下volatile的原理还是上图，当使用volatile修饰后，JVM只会保证从主存加载到线程栈中的变量的值是最新的，这已经可以解释了volatile是如何使处理器总是使用到最新的变量值（依靠上图中蓝色的双向箭头）。 但是，注意但是，凡事都有个意外，volatile也会引发并发取值不一致的情况，原因在这里： 假设有一个线程1和一个线程2，两个线程都会取number变量的值，计算，并写回主存 先是线程1，read和load并计算写回后，number的值发生了变化 再是线程2，当线程2read和load时，可能会是线程1写回并更新之后的number的新值，当线程2计算并写回后，这个number的值还是我们想要的值嘛？ 总结普通状态与加了volatile关键字的对比简单的说，普通状态下，每个线程先从内存拷贝变量值到CPU缓存中（线程工作内存）。当有多个CPU工作时，每个线程可能在不同的CPU上被处理，也就是说，不同的线程使用的变量值都是来自不同的CPU缓存的 而volatile生命的变量就保证了JVM每次读变量都从主存中读取，跳过了CPU缓存这一步 加了volatile关键词后带来的特性 一就是可见性了，因为线程都是从主存读取数据，相当于线程利用主存传递数据 二就是禁止了指令重排序，查看网上的博客，发现了这么一句指令代码lock addl $0x0,(%esp)，这是汇编指令，该操作相当于是一个内存屏障，作用是指令重排序时不能把屏障之后的指令排到屏障之前的位置 日常O_O写这个Blog主要还是被笔试题虐了，关于JVM内存处理机制还是处于比较懵懂的状态，后面买了书再慢慢填坑PS：今天心情爆炸不爽，服。自己还是先狗后人吧。:-)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java序列化]]></title>
      <url>%2F2017%2F03%2F18%2FJava%E5%BA%8F%E5%88%97%E5%8C%96%2F</url>
      <content type="text"><![CDATA[什么是序列化？Java序列化是指把Java对象转换为字节序列的过程；反序列化就是把字节序列再恢复成Java对象的过程 序列化的作用是什么？一般序列化的作用有两方面： 把对象转换成字节序列永久的保存到硬盘上（保存到文件中），在MVC中很好用 在网络上传送对象的字节序列 简单的说，就是把数据（对象）换个时间或者是换个地方，继续使用 换个时间，比如说把数据存盘 换个地方，比如网络间数据的传输 网络间对象的传输我们可以通过网络传输图片、文子、音像、视频等资料，同样也可以传对象，这样两个Java程序间通信就可以交换数据。（云服务，把用户数据从服务器传输给用户等） 如何实现序列化和反序列化？一个不是很难理解的过程，很像是一个处理流 对象流：ObjectOutputStream和ObjectInputStreamObjectOutputStream对象输出流，在实例化时new ObjectOutputStream(OutputStream os)获取输出流，然后writeObject(Object obj)方法可以对参数指定的obj对象进行序列化，然后可以把序列化的的字节序列写到这个os流中；序列化操作1234567File file = new File(file_name);FileOutputStream fos = new FileOutputStream(file);ObjectOutputStream oos = new ObjectOutputStream(fos);// ......Object obj = new Object();oos.writeObject(obj);// ...... 反序列化操作ObjectInputStream对象输出流，在实例化时new ObjectOutputStream(OutputStream os)获取输入流，然后(Object)readObject()方法可以把读取到的字节序列强制转换成某个类的对象，并赋值；1234567File file = new File(file_name);FileInputStream fis = new FileInputStream(file);ObjectInputStream ois = new ObjectInputStream(fis);// ......// 所需的对象字节序列都在流中Object obj = (Object)ois.readObject();// ...... 必备条件只有实现了Serializable或Externalizable接口的类的对象才能被序列化，否则会抛出异常 实现Serializable接口使用默认的序列化/反序列化的方式，对类的非transient的实例对象进行序列化和反序列化 实现Serializable接口并重写了writeObjetct和readObject方法该类对象就可以调用重写后的读写方法 实现Externalizable接口并重写了writeExternal和readExternal方法该类对象可以调用读写方法 直接使用JDK类库上述代码段的使用方式，不再赘述注意对象序列化写入到对象流中的顺序应该与读取对象反序列化时的顺序一致 对于transient关键字的补充 transient只能修饰变量，不能修饰方法和类 被transient修饰的变量不能被序列化；同时，static静态变量不管是否被transient修饰，都不会被序列化 一旦变量被transient修饰，变量将不会被作为持久化对象中的一部分，该变量内容在序列化后不能被访问（变量还在，但变量中的值不在了） 日常总结被虐了……直到现在还在心塞，原理还是不懂，这些Java的小细节可以说是知之甚少，虽然听说过，但怎么用，为什么这么用，实现的原理是什么，一句话都说不出来……关键是还知道这是各种面试笔试都会被提到的高频知识点……讲真的，该去买书看了，JVM、设计模式…… PS：没错，我又开始挖坑了…….剩下的慢慢写好了]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[指针常量和常量指针]]></title>
      <url>%2F2017%2F03%2F18%2F%E6%8C%87%E9%92%88%E5%B8%B8%E9%87%8F%E5%92%8C%E5%B8%B8%E9%87%8F%E6%8C%87%E9%92%88%2F</url>
      <content type="text"><![CDATA[翻看笔试题绕晕了本来翻看着各种笔试题，一切顺利的进行，不会的查一查，记不起来的查一查，直到在看C/C++有关的题目时遇到了 指针常量和常量指针的区别 手动黑人问号懵逼 然后，法式懵逼……一种不祥的预感 然后查了一下，世界懵逼…… 有这么一种通俗易懂的说法查看了好几篇博客，直到看到了这么一种说法：三句箴言： 常量 const ，指针 *，谁排在前先读谁 * 是指针本身，是地址，const是常量本身 const和 * 谁排在前，谁代表的内容就不可以改变举个栗子吧：1234int a = 3;int b = 4;int const *ptr = &amp;a;int* const ptr2 = &amp;b; 在上面的代码中，ptr就是常量指针，ptr2是指针常量；ptr所指向的地址中的内容是常量，所以指向内容不可以改变，但是指向的地址可以改变，比如可以ptr = &amp;b，但是不可以*ptr = bptr2所指向的地址不可以改变，但该地址中的内容可以改变，比如可以*ptr2 = a，但是不可以ptr = &amp;a 注意指针常量因为指向的地址不可更改的原因，在定义时一定要初始化（不能为NULL） 指针常量的用处指针常量有这么两个可靠性方面的优点： 指针不可修改指向，且不能赋值为null 在调用函数时，对于传入的参数可以起到保护的作用，同时还不需要考虑指针为null时的情况 结论其实这是翻译的锅，我们在学习的时候大多用的是翻译过来的说法，如果有心去看一下原文《C Primer plus》，可以看到对于指针常量和常量指针的写法是： 常量指针const pointer 指针常量pointer to const]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java中的优先队列]]></title>
      <url>%2F2017%2F03%2F17%2FJava%E4%B8%AD%E7%9A%84%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97%2F</url>
      <content type="text"><![CDATA[Form一个问题假设百度搜索引擎一天会搜索M亿条URL，如何根据URL被搜索的次数来找出次数最高的N个URL呢？个人有一个抽象的思路： 先对所有的URL日志文档进行整合，同一类型的当作一个结点，利用B或者B+树搜索的优秀性能来处理 再使用优先队列或者是最大值堆来进行一个排序 正确与否先撇开不谈，整合同类URL的过程中会给后续排序减少大量的工作量（但究竟对于这种亿级的数据量还是只有一个朦胧的概念）。不管怎么说，先来研究一下Java中的优先队列好了 优先队列和遍历层次树优先队列（PriorityQueue）是不同于普通队列的先进先出的队列，每次从队列中取出的是具有最高优先权的元素。这是从Java1.5开始引入的数据结构的接口。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// TestPriorityQueue.javaimport java.util.Comparator;import java.util.PriorityQueue;import java.util.Queue;import java.util.Random;class Student&#123; int id; String name; public Student()&#123; this.id = 0; this.name = ""; &#125; public Student(int id, String name) &#123; super(); this.id = id; this.name = name; &#125; public int getId() &#123; return id; &#125; public String getName() &#123; return name; &#125;&#125;public class TestPriorityQueue &#123; private static Comparator&lt;Student&gt; stCompare = new Comparator&lt;Student&gt;()&#123; // 重写了比较器中的compare方法，否则直接把Student类型的元素加入优先队列会报错 @Override public int compare(Student st1,Student st2)&#123; // 针对Student的id属性进行比较 return (int)(st1.getId()-st2.getId()); &#125; &#125;; public static void main(String[] args)&#123; Queue&lt;Integer&gt; number = new PriorityQueue&lt;Integer&gt;();// 存放int类型的数据 Random rand = new Random(); for(int i=0;i&lt;5;i++)&#123; //因为实例化时使用了默认的比较器，所以队列新增的元素时都会自动排序 number.add(rand.nextInt(100)); &#125; for(Integer i : number)&#123; System.out.println(i); &#125; System.out.println(); // ----- 下面开始排序自定义类 // 把重写后的比较器作为参数传入优先队列 Queue&lt;Student&gt; students = new PriorityQueue&lt;Student&gt;(5,stCompare); for(int i=0;i&lt;5;i++)&#123; students.add(new Student(rand.nextInt(10),String.valueOf(i))); &#125; // 预计的输出结果会是：不管st.name是怎样的顺序，但是st.id一定是由小到大 for(Student st : students)&#123; System.out.println(st.id + " " + st.name); &#125; &#125;&#125; 遍历层次树怎么百度的都是概念层次树（黑人问号….），相关的知识有如何层次遍历二叉树，思路是 使其根节点入队列，然后出队进行访问 若左子节点不为空，使左子节点入队 若该节点的右子节点，再使右子节点入队 重复上面三个步骤，直到访问了所有节点 大概的思路是这样，开的坑已经够多了，这个就先放后面好了 /:doge 又回到了HashMap高性能读写方法？其实是自己没有绕出这个圈，那天和dalao讨论的时候，ta认为没有什么优化的方法，毕竟HashMap已经被写好放在jar中了，若是使用，怎么会优化呢？ of cause，自己撸一个HashMap实现，这就引出了一个重点，在我们讨论这个问题的时候，前提是什么？，有说可以自己撸吗？不知道，有说必须要用jdk中的HashMap吗？不知道。 So，……. 来来来，填坑了上次和面试遇到这道题的那个哥们交流了一下，发现了一些意想不到的事情，起始原始的问题是“HashMap放入10W字符串，怎么做可以减少CPU消耗率”他提出了一种解答方式：线程睡眠-每放一定数量的字符串后，就令线程睡眠个1s这…..手动笑哭，显然是延长了程序周期，但是确实CPU消耗率降下来了……. 日常总结今天被教育“凡是遇到问题的时候，第一个想到的就应该是前提条件”，没有前提条件，问题是不受约束的。看似是一个谁都懂的道理，但真的很多时候，会被自己潜意识认为的条件局限了自己的思维。就这样。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[HashMap和HashTable的区别]]></title>
      <url>%2F2017%2F03%2F16%2FHashMap%E5%92%8CHashTable%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
      <content type="text"><![CDATA[日常昨天听说了这么一道题，往HashMap中读写10w条字符串，如何处理可以消耗更少的cpu资源。后面感觉有点蹊跷，不知所以后面问了dalao黄一下，问题是没有解决，但是言语之间似乎有这么一个信息，HashMap和HashTable在存储数据时是有区别的我是想啊，要么HashTable对数据量大的情况下有更好的存储性能？？？，要么是HashTable有更好的并行性？？？ of cause，查一下嘛 区别大概主要的意思是有这么几点区别：两者继承自不同的类，HashMap是HashTable的轻量级实现（非线程安全的实现），但都完成了Map接口 ​HashMap去掉了HashTable中的contains方法，但是加上了containsValue()和containKey()方法 HashTable是同步的，而HashMap是非同步的，由于非线程安全，效率上比HashTable要高 ​HashMap允许空键值，而HashTable不允许 HashMap和HashTable采用的hash/rehash算法大致一样，性能不会差很多 一些其它的小细节 HashMap和Hashtable都实现了Map接口 HashMap是非synchronized，而Hashtable是synchronized HashTable使用Enumeration，HashMap使用Iterator； HashMap的迭代器(Iterator)是fail-fast迭代器，而Hashtable的enumerator迭代器不是fail-fast的。 Hashtable直接使用对象的hashCode，HashMap重新计算hash值，而且用与代替求模 后记好吧，虽然看起来差别不大，但是真的要并行式去存储会不会可以呢？（不晓得啊，其实也不是很懂并行 0.0 ），问题过两天解决了再继续更好了]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[三月中]]></title>
      <url>%2F2017%2F03%2F12%2F%E4%B8%89%E6%9C%88%E4%B8%AD%2F</url>
      <content type="text"><![CDATA[几句随谈前几天听胡哥讲课（正经课），理所当然的提到了鸡汤（这不是日常吗），本着我就静静的看着的心态突然某些话还是触动了什么…遇到不会的解决不了的怎么办？看书上网查资料，还是不会呢？问有经验的人，要还是解决不了呢？ 解决问题而不是解释问题，总想着等我把这个学完了再开始弄这个，什么时候是个头？ 买书！买什么书？酸透了的爱情文学？《二十岁的青春》？愤世嫉俗的批判分析？熟悉人情掌控全局的厚黑学？买了你看了吗？为什么坚持一定要买？ 突然明白了什么其实，有时候努力钻研但是举步维艰而心生退意很正常，我花了这么多时间，回报呢？受益呢？别人这么久都又敲了那么多代码，看了那么厚的书，然而，自己还是没有把问题解决…….可是，看书不会问人，问人再不会再看书，周而复始，没有一点点进步吗？没有一点点收获吗？每一天只要不虚度踏实的学习，不管在干什么，这不都是收获吗？ 总想着不会，不敢，想着先大概了解一下内容，然后再用，再看，确实很低效，但是没有办法，有时候，就是想知道为什么，就是不想稀里糊涂的完成了，这是一种感觉是一种情怀，没有为什么，没有不敢、怂，可是确实和内心的想法有矛盾？ 买书好，一定要花钱，不然不心疼，花钱是一种享受，买了可以不看，太多了的时候可以扔，扔的时候会有一个筛选的过程，尽管可能是不自知的，但一直都认为，提高生活质量的最有效方式就是定期扔东西，something and sometimes，同理 心态本来几天前就该写的，因为周一下午接到了面试电话，约到了周二晚上，怀着忐忑的心准备了，并等待着，等到了电脑没电，等到了深夜，电话没有打来……第一次经历这样的事情（说不清楚心理变化），唯一能想得就只有继续前进，满满的压力，来自四面八方，羡慕dalao，只是希望到自己面对社会时，能感到，还好我做到了]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java反射机制]]></title>
      <url>%2F2017%2F03%2F11%2FJava%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6%2F</url>
      <content type="text"><![CDATA[前言碎语刚开始学习时其实是跳过了这么一个知识点的（因为确定难懂又暂时没什么用），后面听说了在框架中反射是基本的原理，我就又滚回来了（出来混迟早要还的，深以为然） 反射机制是什么？ 反射机制是能在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取信息的以及动态调用对象的方法的功能成为java反射机制 反射是为了动态的加载java类，使得程序在编译时不需要知道某些类的具体信息，只有在运行的时候根据输入的类（补全了某些类的信息），来动态的加载该类，并运行其中的方法。 反射机制有什么用？看过一篇博客，举了这么一个通俗易懂的例子：两个程序员A和B一起工作，因为工作的原因，两个人的任务是分开完成的，同时也是为了保证工程进度；但是程序员A的任务中需要用到程序员B的代码，那么如何在保证A的任务能够进行下去同时又能保证A和B一起推进任务呢？这时就需要用到了java反射的机制。按照上面的说法，我们可以在A的代码中先对所需要B中的某个类进行代理使用，这样可以保证A的程序编译通过；然后在程序运行的时候，通过某种方式（传参数）来获取到真正想要调用的类。这样在程序运行时就会使用到该类的动态代理对象，从而完成任务。 反射机制的原理看了上面的介绍以，我就在想这是怎么实现的（感觉这个反射是为了骗过编译器啊….） 首先说一下动态加载，我们知道jvm在运行java程序前会先加载所使用到的类进行编译，而有的类是在编译时期不知道的，只有在运行的时候才会加载，此谓动态加载。在实现动态加载类时，又有一个动态的代理机制在里面：所谓动态代理，就是程序在运行的时候，对于一个接口和实现类，可以由JVM生成一个代理对象来帮助你使用接口或类中的方法（而不需要显式的去实例化一个类的对象）这样我们可以在程序中直接使用代理对象，完成操作。 反射机制的常规用法对于编译时知道类的信息的情况就不说了，上一篇Class里面有涉及，具体使用时查API文档就好，这里说编译时期不知道类的信息的情况 定义一个动态代理类，该类必须实现InvocationHandler接口 12345678910111213141516171819202122232425262728class DynamicProxy implements InvocationHandler&#123; // 这个是要代理的对象 private Object subject; // 构造方法，给要代理的对象赋初值 public DynamicProxy(Object subject) &#123; this.subject = subject; &#125; @Override public Object invoke(Object object, Method method, Object[] args) throws Throwable &#123; // 在代理真实对象前我们可以添加一些自己的操作 // blablabla... // 当代理对象调用真实对象的方法时，其会自动的跳转到代理对象的invoke方法来进行调用 method.invoke(subject, args); // 在代理真实对象后也可以添加一些操作 // blablabla... return null; &#125;&#125; 使用Class类来获取所需要代理的类；java中Class的用法 1Class testClass = Class.forName(str);// str可以以字符串的形式传入 创建一个动态代理对象并开始使用被代理对象中的方法； 12345678910111213141516171819public class Test&#123; public static void main(String[] args)&#123; // 需要代理的真实对象 Object realObject = new Object(); // 将真实对象传入，最后是通过代理对象来调用其方法的 InvocationHandler handler = new DynamicProxy(realObject); /* * 代理对象obj，通过Proxy的newProxyInstance方法来创建 * 第一个参数 handler.getClass().getClassLoader() ，我们这里使用handler这个类的ClassLoader对象来加载代理对象 * 第二个参数realObject.getClass().getInterfaces()，这里为代理对象提供的接口是真实对象所实现的接口，表示要代理的是该真实对象，这样就能调用这组接口中的方法了 * 第三个参数handler， 将这个代理对象关联到了上方的 InvocationHandler 这个对象上 */ Object obj = (Object)Proxy.newProxyInstance(handler.getClass().getClassLoader(), realObject.getClass().getInterfaces(), handler); obj.wait(10); // 这样使用代理对象来直接调用被代理类的wait方法，并输入参数 &#125; &#125; 这里有需要注意的地方：Proxy的newProxyInstance方法的第二个参数，意思是代理对象去实现了被代理对像的接口，这样代理对象才可以去使用被代理对象实现接口或继承类中的方法。同时如果打印出代理对象的obj.getClass().getName()会显示$proxy0，因为这是JVM自动动态生成的代理对象（与使用时自己初始化代理对象不是一个意思，初始化主要是为了传入被代理对象），这是一种固定的命名方式。 总结反射顺序 创建一个代理类，实现InvkcationHandler接口 重写invoke()方法，并调用method.invoke() 声明真实对象，并传入代理类 声明代理对象，并初始化为Proxy.newProxyInstance()方法获得的实例 使用代理对象调用真实对象的方法 注意 一定要使用Proxy.newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h)方法实例化代理对象 代理类中的invoce(Object proxy, Method method, Object[] args)方法是由代理对象隐式调用的 直接使用代理对象调用真实对象的方法即可 使用反射的利弊优点：反射提高了程序的灵活性以及扩展性，降低了耦合性（依赖关系），提高了程序的适应能力；允许程序在不知道具体类的信息的情况下，创建和控制任何类的对象。 缺点： 性能问题：使用反射时是一种解释操作，用于字段和方法接入时要远慢于直接代码（这事必然啊，总要能理解吧），所以反射机制主要应用于灵活性和扩展性要求很高的系统框架上，普通程序不建议使用 模糊程序内部逻辑：反射绕过了源代码的技术会带来后期的维护问题，毕竟看反射代码更难 总结其实当我们使用编译器，在对象后面加上.时，编译器会自动列出该对象中的所有属性以及方法，这里就用到了这个原理，并称之为java类的自审，可以探知到类的基本结构。 上面的内容都是我在学习时自己提出的问题，越来越感觉在学一个知识点时主动挖掘它的原理是重要的（虽然有的并不需要也并不会想到），开始萌发要看看JVM底层原理的书的念头了….]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java反射之Class初级用法]]></title>
      <url>%2F2017%2F03%2F10%2FJava%E5%8F%8D%E5%B0%84%E4%B9%8BClass%E5%88%9D%E7%BA%A7%E7%94%A8%E6%B3%95%2F</url>
      <content type="text"><![CDATA[Class类Class类的实例表示java应用运行时的类或接口（每个java类在运行的时候都会在JVM里表现为一个Class对象，可以通过类名.Class，类型.getClass()，Class.forName(&quot;包.类名&quot;)等方法获取Class对象） Class类的特点Class类的父类是Object，事实上，任何java类，不管是jdk里面的还是自定义的，都是Class类的对象，同时，所有的数据类型、关键字、方法等等，一切的一切都是Class类的对象。这是前提，很关键 Class类的运行原理java种创建对象时不是通过类直接创建的，一个类的对象被创建之前，首先JVM会加载该类的字节码文件（.class文件），也就是编译后的java程序文件；加载完成后，JVM会自动的为该类创建自己的Class对象，再通过Class对象创建目标对象 使用Class的目的很简单的一句话，可以利用反射机制重新获取到Object对象，这个是动态加载类以及对象的，是在程序运行时才会发生的动作，至于反射机制的具体应用，先挖个坑，以后填 API文档的仿制按照Class类的特性，java种的一切都是Class类的对象，我们可以获取到这些“对象”的信息，比如任意类的属性、构造方法、所有方法等等信息，诚然，我们甚至可以做出一个API文档12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public static void main(String[] args) throws ClassNotFoundException&#123; // 1.返回与带有给定字符串名的类或接口相关联的 Class 对象，直接导致该类被初始化 Class testClass = Class.forName("java.lang.Class"); // 2. 获取该类的实例化对象 Class testClass2 = Class.class; // 3.获取该类的实例化Class对象 Class testClass3 = new Test().getClass(); String target = "([a-zA-Z_-]+)\\."; // 需要匹配的正则表达式，表示了形如“字母+.”的模式，这样便去除了某个类的包名前缀 Class&lt;? super Object&gt; superC = testClass.getSuperclass(); String name = superC.getName(); System.out.print("Class的父类是：" + name.replaceAll(target, "") + "\n"); Constructor&lt;Class&gt;[] consClass = testClass.getDeclaredConstructors(); System.out.println("Class的构造方法有："); for(Constructor con : consClass)&#123; name = con.toString(); name = name.replaceAll(target, ""); System.out.println(name); &#125; Class&lt;Class&gt;[] classes = testClass.getClasses(); System.out.println("Clsass所有的成员的公共类和接口："); if(classes.length==0) System.out.println("null"); for(Class cla : classes)&#123; name = cla.toString(); name = name.replaceAll(target, ""); System.out.println(name); &#125; System.out.println("Class的属性是："); Field[] fields = testClass.getDeclaredFields(); for(Field f : fields)&#123; name = f.toString(); name = name.replaceAll(target, ""); System.out.println(name); &#125; Method[] methods = testClass.getMethods(); System.out.println("Class的所有方法是："); for(int i=0; i&lt;methods.length; i++)&#123; name = methods[i].toString(); name = name.replaceAll(target, ""); System.out.println(name); &#125; ClassLoader loader = testClass.getClassLoader();// 如果对象是基本类型或者是void，则返回null System.out.println("Class的类加载器是：" + loader); 这只是一个简单的思路介绍，重要的是从0到1的过程，至于怎么从1到n，这需要更多的努力。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[深入理解HashMap]]></title>
      <url>%2F2017%2F03%2F05%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3HashMap%2F</url>
      <content type="text"><![CDATA[Hash哈希，译作散列，或哈希。就是把任意长度的输入，通过散列算法（hash算法），变换成固定长度的输出，这个输出的值就是哈希值。显然这是一个映射的过程。 hashCode()再来看一看HashCode，这是一个方法，该方法返回一个特殊的值，在java中会返回一个整数，用来判断是否是两个相同的对象，和equals方法有紧密的联系： HashCode主要用于提供快捷的查找，在HashTable和HashMap中都有使用，HashCode是用来在散列存储结构中确定对象的存储地址的（之所以这样说是因为index的计算与hashCode息息相关） 如果使用equals(Objetc)方法，两个对象相等，那么这两个对象调用hashCode方法返回的值一定是相等的 如果两个对象中的equals方法被重写了，那么一定也要按照同样的方法来重写hashCode方法（这是为了保持hashCode方法的常规协定，规定了相等对象必须有相同的hashCode值） 借用网上看来的文章的一句话：两个对象的hashCode相同（其实更应该说成通过hashCode计算出的index相同），不代表就是同一个对象/两个对象相同，在hash存储结构中，这只说明了两个对象发生了冲突，被分配在了同一个桶里面。java判断两个对象是否相同还会判断对象引用中存储的地址是否相同（默认） Hash函数hash函数，用来计算出哈希值的函数，通常情况下，每一个对象都有自己单独的哈希值，通过hash函数计算出后，可以做到唯一识别。虽然有可能会有冲突的情况出现，出现了同一个hash值，但概率是微乎其微再来n个微乎其微…..hash函数的用途有这么几个：可以这么说，hash就是找到一种数据内容和数据存放地址之间的映射关系。 文件校验：通过对文件摘要，可以对文件进行校验，一定程度上能检测并纠正数据传输中的信道误码，但不能防止对数据的恶意破坏 数字签名：在数字签名协议中，用的最多的单向散列函数可以产生一个机构的数字签名 数据结构中提供快速查找的功能：常用的数据结构HashMap和HashTable会使用到Hash函数来产生hash值，是组成HashMap优越性能必不可少的一环 HashMap在分析这个HashMap之前我们先来看一看数组和链表，我们都知道，数组提供了很好的查找性能，因为数组空间是连续的，查找起来很方便，但是在数据的插入和删除时，性能就不佳了；再看链表，它的存储空间是离散的，所以在数据的插入删除时，性能很高，但是当论到查找时，其性能就不行了。综上所述，我们总是在面对问题时，根据自己的需求来使用不同的数据结构，这是权衡和妥协的结果。那么我们如果能使用到一种数据结构，它提供良好的查找性能，又可以很方便的插入删除。于是乎，把这两种数据结构组合起来就有了我们这个HashTable。↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓从图中可以看出，这是由数组和链表组成的数据结构，在数组中每个元素存储的是一个链表的头指针，把一个个数据存放到相应的位置，就需要由hash函数来计算了，一般是采用index=hash(value)%length计算出元素应该放到对应下标的数组中的位置。比如，如果value为5，数组长度为10，则计算出的下标位置就是5%10=5，这个值应该放到下标为5的元素中。当然了，如果俩个值计算出存放的位置相同了，就以后存入的值为头节点，以链表的形式存入，以此类推 现在回过头来看看HashMap，它其实也是一个线性的数组实现的，所以可以理解为其存储的数据结构就是一个线性数组。但是有一点我们需要注意的就是，HashMap是按照键值对来存取数据的，这一点怎么可能通过数组或是链表来实现呢？ 深入到HashMap的源码中去看，对照着资料，发现在HashMap中存取数据的关键有一个叫做Map.Entry的内部接口很是关键，再去看Entry，发现它被定义为Entry&lt;Key,Value&gt;，而Map.Entry就是一个键值对的实体。如果说HashMap是依靠于数组存储，那么这个数据就是Entry[]，Map存储的内容都在Entry[]里面1234 /** * The table, resized as necessary. Length MUST Always be a power of two. */transient Entry[] table; HashMap存取的实现在“线性数组”的基础上如何做到随机存储呢：重点是确定键值对的存储位置，这里是希望HashMap里面的元素尽量离散分布，使每个位置上的元素只有一个。当使用hash算法求出这个位置时，马上就可以获取对应位置的值，而不用取遍历链表。也与hash方法的离散性能密切相关1234567// hash jdk1.8static final int hash(Object key) &#123; int h; // h = key.hashCode() 为第一步 取hashCode值 // h ^ (h &gt;&gt;&gt; 16) 为第二步 高位参与运算 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 简单说起来，这里的Hash算法本质上就是三步：取key的hashCode的值、高位运算、取模运算对于任意对象，只要hashCode返回值相同，那么程序调用方法所计算的Hash码时一样的，把hash值对数组的长度取模运算，这样元素的分布相对来说是比较均匀的。在上面的方法中，通过把hashCode返回值高16位和低16位与计算，达到了hashCode返回值取模数组长度的效果。因为在HashMap底层数组中，length总是2的n次方（不够的用null填充），此时使用hashCode返回值与数组长度进行与运算依然达到了上述的效果，这是jdk1.7中的实现方法，在1.8中高16位与低16位进行与运算是优化的算法，能保证在hashCode返回值很大时，高低Bit都会参与到hash运算中，并且不会产生较大的开销 put我们知道HashMap中键 Key一定是唯一的，那么当再次往HashMap中存入键相同的键值对时，上一次存入的键值对就会被覆盖。但是如果两个键值对的index值一样时，HashMap会把先存入的值放入链表的尾部，最新加入的值则是该线性数组中每个下标对应的链表的首元素，以此类推。需要注意到的是，jdk1.8新增了HashMap链表中节点的个数对于8个时，转为红黑树的存储方式查看HashMap中的put方法源码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455 public V put(K key, V value) &#123; // 进行hash运算 return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 判断键值对数组table是否为空或null，否则进行resize扩容 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 根据键值key计算hash得到插入位置的索引 if ((p = tab[i = (n - 1) &amp; hash]) == null)// p被赋值 tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; // 判断键值对中key是否存在（相同），存在直接覆盖，相同指hashCode和equals if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 判断是否为树，是的话直接插入新结点 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 链表 else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); // 如果链表的长度大于8就 转化为红黑树处理 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // key已经存在，直接覆盖 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // 存在key的映射 V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 插入成功判断是否超出了最大容量，是就进行扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; reszie的源码是将原来数组的容量扩大一倍，这个过程是一个十分消耗性能的过程，所以在使用中最好定一个预定的最大值，避免HashMap进行频繁的扩容。默认的负载因子是0.75 注意还一个小细节就是，每次put入键值对时，都是先比较key的hashCode，再去使用equals比较key，这样可以节省查重的效率 get首结点都是Entry类型的键值对1234567891011121314151617181920212223242526 public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125; final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // 先检查链表中的首结点 ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; // 判断出了与key相同（hashCode和equals） if ((e = first.next) != null) &#123; // 继续根据hash查找 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 不在首结点，不在红黑树，只能遍历链表 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; null keynull key总是放在Entry[]数组的第一个元素123456789101112131415161718192021private V putForNullKey(V value) &#123; for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123; if (e.key == null) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(0, null, value, 0); return null; &#125; private V getForNullKey() &#123; for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123; if (e.key == null) return e.value; &#125; return null; &#125; 获得索引值indexHashMap存取时需要计算索引index来确认到Entry[]数组取元素的位置，也就是获取数组下标的过程123456 /** * Returns index for hash code h. */static int indexFor(int h, int length) &#123; return h &amp; (length-1);&#125; 按位取并，作用上相当于取模：index = hashcode % table.length hashtable初始大小在调用HashMap的无参构造方法时，初始大小是16。当后续大小改变时，table初始大小总是2的n次方（没有填充满就空着） Hash冲突我们总是希望整个HashMap是一个尽量离散的优秀结构，用尽量少的空间存储尽量多的数据，且其查找增删的性能依据很高效。这个是一个复杂的平衡过程，和负载因子相关，和解决hash冲突的办法相关：hash冲突是指两个key被分配到了同一个桶中，其实就是通过hashCode计算出的index值一样 开放定址法（线性探查再散列、二次探查再散列、为随机探查再散列） 再哈希法 链地址法（拉链法） 建立一个公共的溢出桶java中的HashMap使用的就是拉链法，如前面图所示 再散列过程 rehash当哈希表的容量超过默认的大小时，就需要将所有的元素换一个新的“桶”来存储，这个新的桶中的键值对存放的位置会发生改变，需要重新根据新桶的大小来重新计算各个键值对的索引位置，这个过程就叫做rehash 谈一谈血与泪之所以新加上这个片段就是因为真是彻底的被自己的记性教育了，这真是血淋林的教训啊，已经不记得有几次面试时答错了，这里总结记录一下： HashMap是非线程安全的，HashTable才是线程安全的 HashMap中允许有null键值对，HashTable不允许 总结此次深入探究java中的HashMap查阅了不少资料和源码，感谢先行者的指引，这里仅是个人愚见，如有异议，欢迎联系HashMap实现原理分析java8重新认识HahsMap]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Servlet重定向与转发区别]]></title>
      <url>%2F2017%2F03%2F02%2FServlet%E9%87%8D%E5%AE%9A%E5%90%91%E4%B8%8E%E8%BD%AC%E5%8F%91%E5%8C%BA%E5%88%AB%2F</url>
      <content type="text"><![CDATA[RTservlet在对客户端请求的数据处理之后，会向客户端返回相应的响应结果。这个响应结果可以是由当前servlet对象的PrintWriter输出流直接输出到页面上的信息，也可以是一个新的URL地址对应的信息。在servlet中通过两种方式完成对新URL地址的转向：重定向和请求转发。 URL与URI区别一图胜千言系列 ↓↓↓ 重定向由原请求地址重新定位到某个新地址，原有的请求失效，客户端看到的是新的请求返回的响应结果，客户端浏览器地址栏变为新的请求地址。其中第二次请求是由客户端浏览器自动发出。 请求转发请求转发是将请求再转发到其他地址，转发过程中使用的是同一个请求，转发后浏览器地址栏内容不变。 区别 转发只能将请求转发给同一个web应用（项目工程）中的其他组件（servlet程序）；重定向可以重定向到任意的地址，网络地址或是文件地址（跨项目文件夹） 重定向访问结束后，浏览器地址栏URL发生变化，变成了重定向后的URL；转发则不变 重定向对浏览器的请求直接做出响应，结果就是告诉浏览器去重新发出另一个新的URL访问请求；请求转发在服务器端内部将请求转发给另一个资源，浏览器不知道服务器程序内部发生了转发过程 请求转发调用者与被调用者之间共享相同的请求对象，属于同一个请求和响应过程；重定向则是不同的请求和响应过程]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[alter和update以及drop和delete区别]]></title>
      <url>%2F2017%2F02%2F28%2Falter%E5%92%8Cupdate%E4%BB%A5%E5%8F%8Adrop%E5%92%8Cdelete%E5%8C%BA%E5%88%AB%2F</url>
      <content type="text"><![CDATA[RT使用MySQL时，很多语法相似，容易记浑，比如alter和update，比如drop和delete。 alter和update区别 alter是对表的结构进行的操作，比如增加删除表的字段，或者是修改字段的顺序 update是对表中的数据进行的操作，比如依据某个字段修改当前记录中另一个字段的值 drop和delete区别 drop是对表本体进行的操作，比如删除整张表。如果需要对表的结构进行增删，使用alter delete是对表的数据进行的操作，比如删除某一条记录 总的来说，如果你不想要这张表了，用drop，如果你还想用这张表，只是删除一些数据，用delete]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MySQL使用手册]]></title>
      <url>%2F2017%2F02%2F28%2FMySQL%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C%2F</url>
      <content type="text"><![CDATA[MySQL语法总结MySQL结构：数据库中存放数据都是依托与一张张的数据表存在的，我们通过数据库可以高效的利用数据；而我们对数据的操作就是对数据库中的表的操作。 SQL数据类型：字符型：&lt;varchar&gt; VS &lt;char&gt;文本型：&lt;text&gt;数值型：&lt;int&gt; VS &lt;smallint&gt; VS &lt;tinyint&gt;浮点型：&lt;float&gt; VS &lt;decinal&gt;逻辑型：&lt;bit&gt;日期型：&lt;datetime&gt; VS &lt;smalldatetime&gt; MySQL基本操作（格式）：登陆mysql -u root -p默认没有密码，直接回车，也可以自行修改密码。操作数据库中的表单时，一定要先USE &lt;数据库名&gt;来进入该数据库 创建 创建数据库：CREATE databases &lt;数据库名&gt;; 创建表单：CREATE table &lt;表名&gt;; 查询单表查询：123SELECT &lt;字段名一，字段名二，...&gt;FROM &lt;表名&gt;WHERE &lt;查询条件&gt;; 查询所有数据库：SHOW DATABASE; 选中某个数据库进行操作：USE &lt;数据库名&gt; 查询某数据库中所有的表：SHOW TABLES; 查询表中某字段的数据：SELECT &lt;字段名一,字段名二....&gt; FROM &lt;表名&gt;; 查询某记录：SELECT &lt;字段一,字段二...&gt; FROM &lt;表名&gt; WHERE &lt;查询条件&gt;; （多个）查询条件：&lt;字段名&gt; =值 &amp;&amp; &lt;字段名&gt; =值 查询表中的所有记录：SELECT * FROM &lt;表名&gt;; 查询表结构字段名（不包含外键）：DESC &lt;表名&gt;; 查询表创建时（修改后）的SQL语句：SHOW CREATE TABLE &lt;表名&gt;;可以用来查看外键信息 查询从指定位置开始、一定数量的记录：SELECT &lt;列名&gt; FROM &lt;表名&gt; LIMIT &lt;查询数量&gt; OFFSET &lt;开始位置&gt; ; 连接查询：可以使用表的别名（eg：table1 A） 内连接-等值连接：指使用等号”=”比较两个表的连接列的值，相当于两表执行笛卡尔后，取两表连结列值相等的记录-SELECT &lt;表名A.字段名(*)&gt;,&lt;表名B.字段名(*)&gt; FROM &lt;表名A&gt; INNER JOIN &lt;表名B&gt; ON &lt;表名A.字段名&gt; = &lt;表名B.字段名&gt;; 内连接-非等值连接：SELECT &lt;表名A.字段名(*)&gt;,&lt;表名B.字段名(*)&gt; FROM &lt;表名A&gt; INNER JOIN &lt;表名B&gt; ON &lt;表名A.字段名&gt; &gt;(或者&lt;) &lt;表名B.字段名&gt;; 外连接-左外连接：指将左表的所有记录与右表符合条件的记录匹配，返回的结果除内连接的结果，同时如果有左表不符合条件的记录，就在右表相应列中填NULL-SELECT &lt;表名A.字段名(*)&gt;,&lt;表名B.字段名(*)&gt; FROM &lt;表名A&gt; LEFT JOIN &lt;表名B&gt; ON &lt;表名A.字段名&gt; = &lt;表名B.字段名&gt; 外连接-右外连接：SELECT &lt;表名A.字段名(*)&gt;,&lt;表名B.字段名(*)&gt; FROM &lt;表名A&gt; RIGHT JOIN &lt;表名B&gt; ON &lt;表名A.字段名&gt; = &lt;表名B.字段名&gt; 自然连接：MySQL中的自然连接是自动将两个表中相同名称的列进行记录匹配SELECT &lt;表名A.字段名&gt;,&lt;表名B.字段名&gt; FROM &lt;表名A&gt; NATURAL JOIN &lt;表名B&gt;; 自连接：用别的表实现自身表的连接-SELECT &lt;表名B.字段名(*)&gt; FROM &lt;表名A.字段名(*)&gt;,&lt;表名B.字段名(*)&gt; WHERE &lt;表名A.字段名&gt; = &lt;表名B.字段名&gt; AND &lt;查询条件&gt;; 嵌套查询：将一个查询块嵌套在另一个查询块的WHERE子句或者HAVING短语的条件中的查询 含IN的子查询：可以多层嵌套-SELECT &lt;字段一,字段二...&gt; FROM &lt;表名&gt; WHERE &lt;字段名&gt; IN (SELECT &lt;字段一,字段二...&gt; FROM &lt;表名&gt; WHERE &lt;查询条件&gt;); 含ANY的子查询：查询的条件符合另一个查询结果的任一个即可-SELECT &lt;字段一,字段二...&gt; FROM &lt;表名&gt; WHERE &lt;字段名&gt; &lt;ANY(或者是&gt;ANY、=ANY) (SELECT &lt;字段一,字段二...&gt; FROM &lt;表名&gt; WHERE &lt;查询条件&gt;) 含EXISTS的子查询：EXISTS代表存在量词∃。带有EXISTS谓词的子查询不返回任何数据，只产生逻辑值true或者false-SELECT &lt;字段一,字段二...&gt; FROM &lt;表名&gt; WHERE &lt;字段名&gt; EXISTS (SELECT &lt;字段一,字段二...&gt; FROM &lt;表名&gt; WHERE &lt;查询条件&gt;) 集合查询：SELECT语句的查询结果是元组的集合，所以多个SELECT语句的结果可进行集合操作。集合操作主要包括并操作UNION、交操作INTERSECT、差操作EXCEPT，在MySQL替换过来就是OR、AND、EXISTS/IN 集合并查询：实质上是进行两次查询操作然后将结果取并集-SELECT &lt;字段一,字段二...&gt; FROM &lt;表名&gt; WHERE &lt;查询条件&gt; UNION SELECT &lt;字段一,字段二...&gt; FROM &lt;表名&gt; WHERE &lt;查询条件&gt;，可以使用语句取代-SELECT &lt;字段一,字段二...&gt; FROM &lt;表名&gt; WHERE &lt;查询条件&gt; OR &lt;查询条件&gt; 集合交查询：MySQL不支持直接的交集查询，使用替代语句-SELECT &lt;字段一,字段二...&gt; FROM &lt;表名&gt; WHERE &lt;查询条件&gt; AND &lt;查询条件&gt; 集合差查询：MySQL不支持直接的差集查询-SELECT &lt;字段一,字段二...&gt; FROM &lt;表名&gt; WHERE &lt;查询条件&gt; AND &lt;查询条件&gt;，具体使用时逻辑符号会变。或者使用IN或者EXISTS 排序 按照某字段升序排列：SELECT * FROM &lt;表名&gt; ORDER BY &lt;字段名&gt; LIMIT &lt;待排列的记录数&gt;; 降序排列：SELECT * FROM &lt;表名&gt; ORDER BY &lt;字段名&gt; DESC LIMIT &lt;待排列的记录数&gt;; 插入 插入记录：INSERT INTO &lt;表名&gt; VALUES(&#39;...&#39;,&#39;&#39;,&#39;&#39;,....); 插入某一字段：ALTER TABLE &lt;表名&gt; ADD &lt;字段名&gt; &lt;字段类型&gt; ; 删除 删除数据库：DROP DATABASE &lt;数据库名&gt;; 删除未被外键关联的表：DROP TABLE IF EXISTS &lt;表名&gt;; 删除已经外键关联的表：先删除子表再删除父表 删除表中的某一条记录：DELETE FROM &lt;表名&gt; WHERE &lt;字段=值&gt;; 删除表中的某一字段：ALTER TABLE &lt;表名&gt; DROP &lt;字段名&gt;; 删除外键约束：ALTER TABLE &lt;表名&gt; DROP FOREIGN KEY &lt;外键名&gt; 修改 修改表名：ALTER TABLE &lt;旧表名&gt; RENAME TO &lt;新表名&gt;; 修改表中的字段名：ALTER TABLE &lt;表名&gt; CHANGE &lt;旧字段名&gt; &lt;新字段名&gt; &lt;数据类型&gt;; 修改表中字段的数据类型：ALTER TABLE &lt;表名&gt; MODIFY &lt;字段名&gt; &lt;新数据类型&gt;; 修改表中字段的顺序：ALTER TABLE &lt;表名&gt; MODIFY &lt;字段名&gt; &lt;数据类型&gt; FIRST/AFTER &lt;字段名&gt;; 修改表中某一记录某一字段的值：UPDATE &lt;表名&gt; SET &lt;字段名&gt;=&lt;新值&gt; WHERE &lt;查询条件&gt;; 在表都创建之后添加外键：ALTER TABLE &lt;需要添加外键的表名&gt; ADD CONSTRAINT &lt;外键名&gt; FOREIGN KEY(&lt;需添加外键的表的字段名&gt;) REFERENCES &lt;被作为外键的表名&gt; (&lt;被作为外键的字段名&gt;); 索引index索引可以有重复的值，而unique和primary key索引列中的值时唯一的 ALTER创建索引（可同时添加多个表的索引列） ALTER TABLE &lt;表名&gt; ADD INDEX &lt;索引名（可省缺）&gt;(索引字段名); ALTER TABLE &lt;表名&gt; ADD UNIQUE(&lt;索引字段名&gt;); ALTER TABLE &lt;表名&gt; ADD PRIMARY KEY(&lt;索引字段名&gt;); CREATE增加索引 CREATE INDEX &lt;索引名&gt; ON &lt;表名&gt; (&lt;索引字段名&gt;); CREATE INDEX &lt;索引名&gt; ON &lt;表名&gt; (&lt;索引字段名&gt;); 查询索引：SHOW INDEX FROM &lt;表名&gt;;或者SHOW KEYS FROM &lt;表名&gt;; 删除索引：DROP INDEX &lt;索引名&gt; ON &lt;表名&gt;;或者ALTER TABLE &lt;表名&gt; DROP INDEX &lt;索引名&gt;或者ALTER TABLE &lt;表名&gt; DROP PRIMARY KEY; 设置约束关系主键，又称主码，主键约束就是作为主键的字段在记录中是唯一存在的，不可重复，并且也不许为空。就像我们每个人都有自己唯一的身份ID一样，唯一标识。利用这个特性，我们可以在数据库中快速的查询定位到一条记录。 设置主键：创建表的时候，在定义字段以及数据类型的后面直接加上PRIMARY KEY (默认值)；或者在定义完所有的字段以及数据类型后，加上PRIMARY KEY (&lt;字段名一,....&gt;) 外键，表中的一个或多个字段，可以不是本表的主键，但必须是另一个表的主键。外键用来在两个表中建立连接关系，对于有关联关系的两个表而言，相关联字段中主键所在的表为父表，外键所在的表为子表。 设置外键：在表中所有字段都定义后（包括外键名），加上CONSTRAINT &lt;外键约束名&gt; FOREIGN KEY(外键名) REFERENCES &lt;关联的外表名(外表的字段名)&gt;; 注意的是，这里的外键约束名与外键名是不同的意思同一个数据库中，外键约束名和外键名一定不可以重复！！！ /(ㄒoㄒ)/~~ 视图视图包含行和列，其中的字段来自一个或多个数据库中的真实的表中的字段，一起组合成一个类似真实的表。可以像基本表一样，进行增删改查的操作。记录进行改动后，视图与基本表都会更新 创建视图： 1234CREATE VIEW &lt;视图名&gt;(视图字段名一,字段名二,...(可选)) AS &lt;子查询语句&gt;SELECT &lt;字段名一,字段名二,...&gt;FROM &lt;表名&gt;WHERE &lt;查询条件&gt;; 删除视图：DROP VIEW &lt;视图名&gt;; 查询视图：SELECT * FROM &lt;视图名&gt;;或者SLECT &lt;字段名&gt; FROM &lt;视图名&gt;; 修改视图：可以向上述修改字段/记录的方式一样来修改视图，并且修改结果各个实际的表也会生效，也可以按下面的方法修改↓↓↓↓↓1234CREATE OR REPLACE VIEW &lt;视图名&gt;(视图字段名一,字段名二,...(可选)) AS &lt;子查询语句&gt;SELECT &lt;字段名一,字段名二,...&gt;FROM &lt;表名&gt;WHERE &lt;查询条件&gt;; 某些情况下可以缺省视图的字段名，MySQL会自动补全。但是当SELECT后面的字段有来自函数查询的结果时，不可以缺省。 添加注释/备注 给表添加描述：ALTER TABLE &lt;表名&gt; COMMENT=&#39;这里是表的注释&#39; 给列添加描述：ALTER TABLE &lt;表名&gt; MODIFY &#39;&lt;字段名&gt;&#39; DATETIME DEFAULT NULL COMMENT &#39;字段描述&#39; 心得谈一谈外键约束关系：在两个相关联的表中，一个表的主键是另一个表的非主键字段，这个字段中的值可能有很多。就拿学生选课来说，某一个课程可能有很多学生选，学生的主键是学号，那么该课程的表中，学号这一外键就会有很多值，同时，也把课程的数据表和学生的数据表关联了起来。呐，在这个例子中，课程的表就是子表，学生的数据表就是父表。倘若，父表的值改变了，那么一定需要修改子表的值，而子表想去修改外键的值是没有权限的；但是，子表可以删除带有外键值的记录。这之中就有一种很明显的约束关系。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Eclipse编写jsp自动导入包]]></title>
      <url>%2F2017%2F02%2F27%2FEclipse%E7%BC%96%E5%86%99jsp%E8%87%AA%E5%8A%A8%E5%AF%BC%E5%85%A5%E5%8C%85%2F</url>
      <content type="text"><![CDATA[RT使用eclipse我们会需要一个自动补全剩余代码的功能，这使得我们可以在输完一些变量或者方法甚至是包的时候，可以方便快捷的选择我们想要输入的内容。very convenient！~ 这个关键性的组合按键就是：alt + / 当然了，这个在写java程序的时候可以使用，在写jsp程序的时候，依然是这个组合键 QvQ]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java中几个获取长度的方法区别]]></title>
      <url>%2F2017%2F02%2F27%2FJava%E4%B8%AD%E5%87%A0%E4%B8%AA%E8%8E%B7%E5%8F%96%E9%95%BF%E5%BA%A6%E7%9A%84%E6%96%B9%E6%B3%95%E5%8C%BA%E5%88%AB%2F</url>
      <content type="text"><![CDATA[length和length()和size()lengthlength是数组的属性，直接使用.来进行访问，用来获取数组的长度。 length()length()是一个方法，针对的是String类型，用来获取字符串的长度。 size()size()是方法，用于获取泛型集合的大小，以便了解其中的元素个数。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java线程]]></title>
      <url>%2F2017%2F02%2F27%2FJava%E7%BA%BF%E7%A8%8B%2F</url>
      <content type="text"><![CDATA[java线程体会为什么需要使用线程：​ 我们知道，一般程序都是以一个由上至下的运行方式运行的，不完成上一步的时候，是无法进入下一步的执行的。可是我们有时候需要在一个程序同时去做两个不同的任务，各自之间互不干涉，那么根据程序的执行过程，该如何解决呢？ ​ 答案就是使用线程，所谓线程，就是一个程序中最小的执行单元，一个程序在运行时就是一个进程，一个进程可以包含多个线程，这样就允许了一个程序同时去做不同的任务。所以总结的说，我们需要使用线程来让程序在同一时间做不同的事情，并且互不干涉。 注： 程序是包含了所有执行文件、数据文件、图像文件以及各种文档的资源集合，存储在电脑磁盘里 进程是一个程序在运行时所需要的所有资源集合，包含了代码、数据、堆栈、变量等，就像一台电脑。 线程是进程的子集，每一个线程可以看作是进程中的一个执行单元，就像CPU。 线程的基本特点：在不同的语言中，线程有不同的实现方式，但都有共同的基本特征： 没有属于自己的内存空间，所有使用的空间都是由进程统一安排分配 在线程中使用的数据会存放到属于自己的栈中，但栈中的数据我们是知道的，是不会保留下来的 :cry: 线程的上下文切换是比进程要快很多倍的，而且新建一个线锁需要的时间开销也是少于进程的；但有优点就一定会有缺点，线程的开销是很大的，每创建一个线程都至少要分配512KB甚至是1MB字节的内存，还有的线程及进程的区别可以去看有关操作系统的书 使用线程的方法： 继承Thread类 实现Runnable接口 使用使用ExecutorService（线程池接口）、Callable（重写call()方法）、Future实现有返回结果的多线程(JDK5.0以后) 虽然都可以实现线程的控制，但是我们在实际中却用到第二种方法比较多，原因就是我们有时候需要继承不止一个类，这时如果我们不去实现Runnable接口，我们该如何使这个类编程线程类呢？:happy: 实现线程类需要注意的地方： 我们想让线程去做的任务都写在run方法里 线程类创建后我们需要去启动线程，而不是调用run方法，不然就仍旧还是方法调用 启动线程的方法 实现Runnable接口： 1234567891011class Ball implements Runnable&#123; public void run()&#123; System.out.println("hello thread"); //我们想使用多线程实现的内容 &#125;&#125;class UseBall &#123; Ball ball = new Ball(); new Thread(ball).start();&#125; 继承Thrad类：1234567891011class Ball extends Thread&#123; public void run()&#123; System.out.println("hello thread"); //我们想使用多线程实现的内容 &#125;&#125;class UseBall &#123; Ball ball = new Ball(); ball.start();&#125; 使用线程进行操作的时候注意添加异常操作12345678910111213141516171819public static void main(String[] args) &#123; // TODO Auto-generated method stub ExecutorService singleThreadExecutor = Executors.newSingleThreadExecutor(); for(int i=0; i&lt;10; i++)&#123; final int index = i; singleThreadExecutor.execute(new Runnable()&#123; public void run()&#123; System.out.println(index); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125;); &#125; &#125; 总结​ 综上所述，线程的使用方法以及一些特点就在这里了。个人理解其使用的条件就是想让程序同时完成不同的任务时，使用多线程实现。 ​ 多线程是java重要的的特点之一，利用多线程我们可以完成很多特殊的功能，比如：弹球游戏、坦克大战和聊天室等等。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[writeUTF学习]]></title>
      <url>%2F2017%2F02%2F27%2FwriteUTF%E5%AD%A6%E4%B9%A0%2F</url>
      <content type="text"><![CDATA[流式输出对象的writeUTF()方法记录如何使用字节数组来进行数据的传输 InputStream / OutputStream作为所有输入输出流的父类，其方法read和write DataInputStream / DataOutputStream处理流，包含了很多对数据的处理方法readInt，readFully和writeInt，write。另外因为是处理流，需要套在节点流上使用，故构造方法需要一个参数InputStream / OutputStream InputStraemReader该类一个接收System.in输入的内容 BufferedReader可以将InputStreamReader流中的内容当成字符串整行的读取出来 flush() / close()所有的输出流在写完后最好都强制刷新一下缓冲flush，程序接收后把整个输入输出流关掉]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Socket通信字节流or字符流]]></title>
      <url>%2F2017%2F02%2F27%2FSocket%E9%80%9A%E4%BF%A1%E5%AD%97%E8%8A%82%E6%B5%81or%E5%AD%97%E7%AC%A6%E6%B5%81%2F</url>
      <content type="text"><![CDATA[socket通信选择字节流还是字符流？字符流处理的单元为2个字节的字符，分别操作字符、字符数组或字符串，而字节流处理单元为1个字节，操作字节和字节数组。所以字符流是由Java虚拟机将字节转化为2个字节的字符为单位的字符而成的，所以它对多国语言支持性比较好！如果是音频文件、图片、歌曲，就用字节流好点，如果是关系到中文（文本）的，用字符流好点。 所有文件的储存是都是字节（byte）的储存，在磁盘上保留的并不是文件的字符而是先把字符编码成字节，再储存这些字节到磁盘。在读取文件（特别是文本文件）时，也是一个字节一个字节地读取以形成字节序列 1.字节流可用于任何类型的对象，包括二进制对象，而字符流只能处理字符或者字符串；2.字节流提供了处理任何类型的IO操作的功能，但它不能直接处理字符，而字符流就可以 字节流是最基本的，所有的InputStrem和OutputStream的子类都是,主要用在处理二进制数据，它是按字节来处理的 但实际中很多的数据是文本，又提出了字符流的概念，它是按虚拟机的encode来处理，也就是要进行字符集的转化。这两个之间通过 InputStreamReader,OutputStreamWriter来关联，实际上是通过byte[]和String来关联，在实际开发中出现的汉字问题实际上都是在字符流和字节流之间转化不统一而造成的]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[linux终端配色方案]]></title>
      <url>%2F2017%2F02%2F27%2Flinux%E7%BB%88%E7%AB%AF%E9%85%8D%E8%89%B2%E6%96%B9%E6%A1%88%2F</url>
      <content type="text"><![CDATA[Ubuntu终端配色骚年，看到单调的黑色背景的终端是不是感觉很乏味？试试这个教程吧，可以使终端变的beautiful~ First使用快捷键ctrl + alt + T打开终端键入gedit ~/.bashrc会弹出一个编辑文本，复制粘贴下面的代码到文件的最后部分：1PS1=&apos;$&#123;debian_chroot:+($debian_chroot)&#125;\[\033[01;35;01m\]\u\[\033[00;00;01m\]@\[\033[01;35;01m\]\h\[\033[00;31;01m\]:\[\033[00;00;01m\]\w \[\033[01;32;01m\]\$ \[\033[01;01;01m\]&apos; 注意代码两边的冒号‘。保存后退出即可。 Second关闭终端后重新打开终端，可以看到，终端的配色方案已经有了变化。然后，在终端中点击鼠标右键，选择下面的选项然后选择Background标签，勾选上Transparent background选项，这是打开终端背景透明的选项。 Final设置后透明度之后，点击close即可，这时你的终端就会变的很好(炫)看(闪)了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[github上传项目]]></title>
      <url>%2F2017%2F02%2F27%2Fgithub%E4%B8%8A%E4%BC%A0%E9%A1%B9%E7%9B%AE%2F</url>
      <content type="text"><![CDATA[RT今天下午突发奇想，打开了小站，然后顺便打开了github，于是想上传曾经做过的项目，本来想按照之前传博客的方法去传项目，然后发现，好像哪里不太对劲，仔细一看教程，确实不太一样。于是乎就去找github上传本地项目的方法，下面总结一下自己的试坑过程。 First-创建本地仓库首先要在自己的本地磁盘内创建一个文件夹，名字自己随便取，用来当作自己本地存放项目并且用来和github交互的仓库。我这里创建一个名为 mygit的文件夹。 Second-在github上创建项目仓库登陆自己的github，然后新建仓库，项目名字自己取，我这里取了try这个名字。勾选项和我的设置保持一致即可。 Third-设置ssh密钥git shell程序随便选一个安装，打开shell后，输入命令：ssh-keygen -C &#39;your@email.address&#39; -t rsa注意的是，这个 ‘ ‘ 中的内容就是你的github账号，因为一般是用邮箱注册的。然后不需要管弹出什么内容，什么请输入密码啊什么的，联系按三个回车键，然后在你的电脑的用户目录下找一个名为.ssh的文件夹。打开其中的id_rsa.pub文件，然后复制全部的内容。接着打开你github项目设置里面，左侧栏有一个选项SSH and GPG Keys，打开后，点击右上角的new SSH key按钮，title栏随便输入提示性，key栏把刚才复制的内容全部粘贴进去。确认后会显示一把绿色的小钥匙。 完成上述步骤后，在git shell中输入命令ssg -T git@github.com，注意，这里需要是大写的-T，不知道怎么回事，我输入小写的t就是不行。正确的显示结果如下：则表明已经成功连接至你的github库了。 Fouth-“装填”项目文件在git shell运行命令：git clone https://github.com/your name/you program name.git其实后面的链接就是你打开你的github项目中的仓库后，网页中网址链接，复制粘贴即可。这个时候会在你本地仓库目录中生成文件夹，名字就是你的项目的名字，同时还会有一个隐藏的.git文件。在我举的这个例子中，这个文件夹就是try。然后，只需要把想要上传到仓库中的项目文件全部放到这个文件夹中就好了，我的话就是把项目文件放入到try文件夹中就好。 然后，在git shell中输入以下命令：git initgit add xxx （注意这个名字就是想上传文件夹的名字，没有&#39; &#39;）git commit -m &#39;your-program-name&#39; （这里有&#39; &#39;，内容也是想上传文件夹的名字），一定注意要先add文件注意这里可能会有错误，↓↓↓↓↓↓↓↓↓↓↓↓↓↓那就使用git commit -am &quot;your-program-name&quot;这条命令再继续 如果正确，会有类似的显示结果：然后继续输入git remote add origin https://github.com/your-name/you-program-name.git这里可能会出现错误↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓那就使用git remote rm origin，在继续下一步thengit pull origin master这里会即进入Vi编辑器的界面，是需要你输入merge的理由，随便写，不会vim编辑器语法的我后面讲。git push origin master如果步骤都正确，会有这样的过程和结果： 总结上述步骤有些复杂，一般情况下可以使用更为简单的12345git add xxxgit commit -m &quot;这次提交的备注信息&quot;git push -u origin master Attention这里简单说一下vim编辑器的使用吧，本次操作只需要两个命令即可：i 开始进行编辑内容:wq 编辑完成后，按Esc，进入命令界面，输入:wq，表示保存及退出 Final到此为止，已经正确上传了项目到你自己的github中，以后也可以重复上面除了新建ssh密钥的步骤外别的操作来继续上传。当然了，如果只需要修改部分文件或者是上传部分文件，又或者是有其他github的操作，请自行移步git使用教程。当然了，以后我自己也会进行某些内容更新。QvQ2017.04.09补充：Github桌面版简化了很多步骤，方便的一批]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[hexo生成博文插入图片]]></title>
      <url>%2F2017%2F02%2F26%2Fhexo%E7%94%9F%E6%88%90%E5%8D%9A%E6%96%87%E6%8F%92%E5%85%A5%E5%9B%BE%E7%89%87%2F</url>
      <content type="text"><![CDATA[RT十分痛苦，是因为突然发现上传的博客里面的图片居然显示不来，excuse me???笋干shabi了怎么办，上网google解决之道，然后又试了很多坑…….更加绝望了…..然后，看到了这个：dalao指导hhhh，再试一次….. 然而，居然可以了….excuse me?? 好吧，总结一下这个牛批的解决办法： First1 把主页配置文件_config.yml 里的post_asset_folder:这个选项设置为true 2 在你的hexo目录下执行这样一句话npm install hexo-asset-image --save，这是下载安装一个可以上传本地图片的插件，来自dalao：dalao的git 3 等待一小段时间后，再运行hexo n &quot;xxxx&quot;来生成md博文时，/source/_posts文件夹内除了xxxx.md文件还有一个同名的文件夹 Second4 最后在xxxx.md中想引入图片时，先把图片复制到xxxx这个文件夹中，然后只需要在xxxx.md中按照markdown的格式引入图片： ![你想输入的替代文字](xxxx/图片名.jpg) 注意：xxxx是这个md文件的名字，也是同名文件夹的名字，你想引入的图片就只需要放入xxxx这个文件夹内就好了，很像引用相对路径。 5 最后检查一下，hexo g生成页面后，进入public\2017\02\26\index.html文件中查看相关字段，可以发现，html标签内的语句是&lt;img src=&quot;2017/02/26/xxxx/图片名.jpg&quot;&gt;，而不是&lt;img src=&quot;xxxx/图片名.jpg&gt;。这很重要，关乎你的网页是否可以真正加载你想插入的图片。 总结一下这个跳（试）坑的过程首先是有句mmp想讲，实在是有点坑 但是，似乎又多了一项学（zhuang）习（bi）技巧 hhh，先到这里，后面还有一个坑就是，想引入某些dalao 的链接时，如果链接里包含中文，那么再写入md文件里生成网页后这个链接就打不开了….. 待老夫研究后再填坑，后面如果有时间，就把自己搭建网站的过程码一下。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Final]]></title>
      <url>%2F2017%2F02%2F21%2FFinal%2F</url>
      <content type="text"><![CDATA[第一天的总结差不多先折腾到这里吧，大概已有的功能呢，有添加博客和归档的标签，以后还会完成自己的个人简历 Q^Q 说到了这里，这两天自己摸索着使用github来搭建自己的个人网站确实受益良多，贴出大腿的指导书： https://volc1605.github.io/2016/10/03/Hexo之NexT主题搭建博客详细过程 暂时的尝试先到此为止，明后天看看能不能再去抢个腾讯的服务器吧，fightting！骚年]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[f__k? this day]]></title>
      <url>%2F2017%2F02%2F21%2Ffuck%2F</url>
      <content type="text"><![CDATA[Today今天是特别的一天，忙碌了一整天的时间来学习搭建个人网站博客。到现在为止，略有小成，先写下这一篇随笔，然后全当做实验了。 ps:没有大腿抱确实一个人折腾好累pss:折腾完又有种莫名的兴奋感……QvQ]]></content>
    </entry>

    
  
  
</search>
